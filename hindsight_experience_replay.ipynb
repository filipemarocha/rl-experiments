{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_simple\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(10)\n",
      "Box(5, 5, 5, 5, 5, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('PutBallInBoxEnvRandom5x5-v0')\n",
    "\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "\n",
    "actions = ['up', 'down', 'left', 'right', 'up-right', 'up-left',\n",
    "    'down-right', 'down-left', 'pick-up', 'put-down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork:\n",
    "    def __init__(self, learning_rate, state_size, action_size, hidden_size, name='QNetwork'):\n",
    "        with tf.variable_scope(name):\n",
    "            # State inputs to the Q-network\n",
    "            self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "\n",
    "            # One hot encode the actions to later choose the Q-value for the action\n",
    "            self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "\n",
    "            # Target Q values for training\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "\n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, hidden_size)\n",
    "            \n",
    "            # Linear hidden layer\n",
    "            self.fc3 = tf.contrib.layers.fully_connected(self.fc2, hidden_size,\n",
    "                                                         activation_fn=None)\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc3, action_size,\n",
    "                                                            activation_fn=None)\n",
    "\n",
    "            # Minimize loss: (targetQ - Q)^2\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment specific parameters\n",
    "action_size = env.action_space.n\n",
    "state_size = len(env.observation_space.shape)\n",
    "\n",
    "# Training parameters\n",
    "train_episodes = 1000         # max number of episodes to learn from\n",
    "max_steps = 1000              # max steps in an episode\n",
    "gamma = 0.95                  # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0           # exploration probability at start\n",
    "explore_stop = 0.1            # minimum exploration probability\n",
    "decay_rate = 0.0001          # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 100             # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001        # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 50000           # memory capacity\n",
    "batch_size = 5000             # experience mini-batch size\n",
    "pretrain_length = batch_size  # number experiences to pretrain the memory\n",
    "\n",
    "# Update Target Network\n",
    "c_steps = 100                  # every c steps\n",
    "\n",
    "# Proportion of HER replay to standard replay\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self, max_transitions=1000, max_goals=1000):\n",
    "        self.buffer = deque(maxlen=max_transitions)\n",
    "        self.goals = deque(maxlen=max_goals)\n",
    "\n",
    "    def add_goal(self, goal_state):\n",
    "        self.goals.append(goal_state)\n",
    "\n",
    "    def sample_goals(self, n_goals):\n",
    "        if len(self.goals) >= n_goals:\n",
    "            idx = np.random.choice(np.arange(len(self.goals)),\n",
    "                                   size=n_goals,\n",
    "                                   replace=False)\n",
    "            return [self.goals[ii] for ii in idx]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    # experience: (state, action, reward, next_state)\n",
    "    def add_transition(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample_transitions(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)),\n",
    "                               size=batch_size,\n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "state, reward, done, _ = env.reset()\n",
    "\n",
    "memory = Memory(max_transitions=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for ii in range(pretrain_length):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    #env.render()\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    goals_sample = memory.sample_goals(k)\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        #next_state = np.zeros(state.shape)\n",
    "        # Add experience to memory\n",
    "        memory.add_transition((state, action, reward, next_state))\n",
    "        for goal in goals_sample:\n",
    "            if np.array_equal(next_state, goal):\n",
    "                memory.add_transition((state,action,100,next_state))\n",
    "            else:\n",
    "                memory.add_transition((state,action,-1,next_state))\n",
    "        # Start new episode\n",
    "        state, reward, done, _ = env.reset()\n",
    "\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add_transition((state, action, reward, next_state))\n",
    "        for goal in goals_sample:\n",
    "            if np.array_equal(next_state, goal):\n",
    "                memory.add_transition((state,action,100,next_state))\n",
    "            else:\n",
    "                memory.add_transition((state,action,-1,next_state))\n",
    "        state = next_state\n",
    "\n",
    "goals_sample = memory.sample_goals(k)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mainQN = QNetwork(name='main', hidden_size=hidden_size, state_size=state_size, \n",
    "                  action_size=action_size, learning_rate=learning_rate)\n",
    "targetQN = QNetwork(name='target', hidden_size=hidden_size, learning_rate=learning_rate,\n",
    "                   action_size=action_size, state_size = state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetNetwork(tfVars):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign(var.value()))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n",
      "-1000.0\n",
      "Episode: 2\n",
      "Reached the goal after 453 timesteps\n",
      "Episode: 2 Training loss: 0.0521 Explore P: 0.8782\n",
      "-676.5\n",
      "Episode: 3\n",
      "-784.3333333333334\n",
      "Episode: 4\n",
      "-838.25\n",
      "Episode: 5\n",
      "Reached the goal after 232 timesteps\n",
      "Episode: 5 Training loss: 0.2405 Explore P: 0.7225\n",
      "-697.0\n",
      "Episode: 6\n",
      "-747.5\n",
      "Episode: 7\n",
      "Reached the goal after 245 timesteps\n",
      "Episode: 7 Training loss: 0.9798 Explore P: 0.6495\n",
      "-661.4285714285714\n",
      "Episode: 8\n",
      "-703.75\n",
      "Episode: 9\n",
      "Reached the goal after 573 timesteps\n",
      "Episode: 9 Training loss: 1.7661 Explore P: 0.5695\n",
      "-678.1111111111111\n",
      "Episode: 10\n",
      "Reached the goal after 61 timesteps\n",
      "Episode: 10 Training loss: 3.4501 Explore P: 0.5666\n",
      "-606.4\n",
      "Episode: 11\n",
      "Reached the goal after 377 timesteps\n",
      "Episode: 11 Training loss: 5.5398 Explore P: 0.5493\n",
      "-576.4545454545455\n",
      "Episode: 12\n",
      "Reached the goal after 159 timesteps\n",
      "Episode: 12 Training loss: 4.5276 Explore P: 0.5422\n",
      "-533.3333333333334\n",
      "Episode: 13\n",
      "Reached the goal after 254 timesteps\n",
      "Episode: 13 Training loss: 2.1325 Explore P: 0.5310\n",
      "-504.15384615384613\n",
      "Episode: 14\n",
      "Reached the goal after 193 timesteps\n",
      "Episode: 14 Training loss: 8.1115 Explore P: 0.5228\n",
      "-474.7857142857143\n",
      "Episode: 15\n",
      "Reached the goal after 176 timesteps\n",
      "Episode: 15 Training loss: 4.9785 Explore P: 0.5153\n",
      "-448.2\n",
      "Episode: 16\n",
      "Reached the goal after 24 timesteps\n",
      "Episode: 16 Training loss: 1.6482 Explore P: 0.5143\n",
      "-415.4375\n",
      "Episode: 17\n",
      "Reached the goal after 498 timesteps\n",
      "Episode: 17 Training loss: 2.7234 Explore P: 0.4941\n",
      "-414.4117647058824\n",
      "Episode: 18\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 18 Training loss: 7.9225 Explore P: 0.4938\n",
      "-386.22222222222223\n",
      "Episode: 19\n",
      "Reached the goal after 262 timesteps\n",
      "Episode: 19 Training loss: 7.8442 Explore P: 0.4836\n",
      "-374.42105263157896\n",
      "Episode: 20\n",
      "Reached the goal after 192 timesteps\n",
      "Episode: 20 Training loss: 1.9536 Explore P: 0.4763\n",
      "-360.3\n",
      "Episode: 21\n",
      "Reached the goal after 90 timesteps\n",
      "Episode: 21 Training loss: 6.6822 Explore P: 0.4729\n",
      "-342.6666666666667\n",
      "Episode: 22\n",
      "Reached the goal after 313 timesteps\n",
      "Episode: 22 Training loss: 4.4231 Explore P: 0.4613\n",
      "-336.77272727272725\n",
      "Episode: 23\n",
      "Reached the goal after 70 timesteps\n",
      "Episode: 23 Training loss: 5.4643 Explore P: 0.4588\n",
      "-320.82608695652175\n",
      "Episode: 24\n",
      "Reached the goal after 853 timesteps\n",
      "Episode: 24 Training loss: 7.8338 Explore P: 0.4294\n",
      "-338.8333333333333\n",
      "Episode: 25\n",
      "Reached the goal after 39 timesteps\n",
      "Episode: 25 Training loss: 6.8549 Explore P: 0.4281\n",
      "-322.84\n",
      "Episode: 26\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 26 Training loss: 4.8186 Explore P: 0.4278\n",
      "-306.84615384615387\n",
      "Episode: 27\n",
      "Reached the goal after 107 timesteps\n",
      "Episode: 27 Training loss: 9.2136 Explore P: 0.4243\n",
      "-295.74074074074076\n",
      "Episode: 28\n",
      "Reached the goal after 121 timesteps\n",
      "Episode: 28 Training loss: 7.3590 Explore P: 0.4204\n",
      "-285.92857142857144\n",
      "Episode: 29\n",
      "Reached the goal after 692 timesteps\n",
      "Episode: 29 Training loss: 10.1829 Explore P: 0.3989\n",
      "-296.48275862068965\n",
      "Episode: 30\n",
      "Reached the goal after 217 timesteps\n",
      "Episode: 30 Training loss: 9.7526 Explore P: 0.3925\n",
      "-290.5\n",
      "Episode: 31\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 31 Training loss: 7.2246 Explore P: 0.3923\n",
      "-278.06451612903226\n",
      "Episode: 32\n",
      "Reached the goal after 131 timesteps\n",
      "Episode: 32 Training loss: 5.1399 Explore P: 0.3885\n",
      "-270.34375\n",
      "Episode: 33\n",
      "Reached the goal after 335 timesteps\n",
      "Episode: 33 Training loss: 5.7363 Explore P: 0.3789\n",
      "-269.27272727272725\n",
      "Episode: 34\n",
      "Reached the goal after 89 timesteps\n",
      "Episode: 34 Training loss: 6.4791 Explore P: 0.3764\n",
      "-261.02941176470586\n",
      "Episode: 35\n",
      "Reached the goal after 837 timesteps\n",
      "Episode: 35 Training loss: 9.0229 Explore P: 0.3542\n",
      "-274.62857142857143\n",
      "Episode: 36\n",
      "Reached the goal after 90 timesteps\n",
      "Episode: 36 Training loss: 7.2549 Explore P: 0.3519\n",
      "-266.72222222222223\n",
      "Episode: 37\n",
      "Reached the goal after 127 timesteps\n",
      "Episode: 37 Training loss: 6.6338 Explore P: 0.3487\n",
      "-260.2432432432432\n",
      "Episode: 38\n",
      "Reached the goal after 45 timesteps\n",
      "Episode: 38 Training loss: 7.9558 Explore P: 0.3476\n",
      "-251.94736842105263\n",
      "Episode: 39\n",
      "Reached the goal after 52 timesteps\n",
      "Episode: 39 Training loss: 4.5059 Explore P: 0.3463\n",
      "-244.25641025641025\n",
      "Episode: 40\n",
      "Reached the goal after 31 timesteps\n",
      "Episode: 40 Training loss: 10.1814 Explore P: 0.3455\n",
      "-236.425\n",
      "Episode: 41\n",
      "Reached the goal after 54 timesteps\n",
      "Episode: 41 Training loss: 11.1972 Explore P: 0.3441\n",
      "-229.53658536585365\n",
      "Episode: 42\n",
      "Reached the goal after 18 timesteps\n",
      "Episode: 42 Training loss: 7.4569 Explore P: 0.3437\n",
      "-222.11904761904762\n",
      "Episode: 43\n",
      "Reached the goal after 128 timesteps\n",
      "Episode: 43 Training loss: 7.4490 Explore P: 0.3405\n",
      "-217.6046511627907\n",
      "Episode: 44\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 44 Training loss: 10.0985 Explore P: 0.3400\n",
      "-210.86363636363637\n",
      "Episode: 45\n",
      "Reached the goal after 87 timesteps\n",
      "Episode: 45 Training loss: 6.2747 Explore P: 0.3379\n",
      "-205.88888888888889\n",
      "Episode: 46\n",
      "Reached the goal after 72 timesteps\n",
      "Episode: 46 Training loss: 6.8221 Explore P: 0.3362\n",
      "-200.80434782608697\n",
      "Episode: 47\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 47 Training loss: 9.1264 Explore P: 0.3359\n",
      "-194.63829787234042\n",
      "Episode: 48\n",
      "Reached the goal after 93 timesteps\n",
      "Episode: 48 Training loss: 6.8758 Explore P: 0.3337\n",
      "-190.4375\n",
      "Episode: 49\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 49 Training loss: 4.4335 Explore P: 0.3335\n",
      "-184.69387755102042\n",
      "Episode: 50\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 50 Training loss: 11.8755 Explore P: 0.3332\n",
      "-179.24\n",
      "Episode: 51\n",
      "Reached the goal after 145 timesteps\n",
      "Episode: 51 Training loss: 8.9629 Explore P: 0.3298\n",
      "-176.6078431372549\n",
      "Episode: 52\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 52 Training loss: 7.3452 Explore P: 0.3297\n",
      "-171.34615384615384\n",
      "Episode: 53\n",
      "Reached the goal after 99 timesteps\n",
      "Episode: 53 Training loss: 9.6364 Explore P: 0.3274\n",
      "-168.0943396226415\n",
      "Episode: 54\n",
      "Reached the goal after 124 timesteps\n",
      "Episode: 54 Training loss: 15.8468 Explore P: 0.3246\n",
      "-165.42592592592592\n",
      "Episode: 55\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 55 Training loss: 10.4498 Explore P: 0.3243\n",
      "-160.78181818181818\n",
      "Episode: 56\n",
      "Reached the goal after 56 timesteps\n",
      "Episode: 56 Training loss: 12.6596 Explore P: 0.3230\n",
      "-157.125\n",
      "Episode: 57\n",
      "Reached the goal after 141 timesteps\n",
      "Episode: 57 Training loss: 13.3433 Explore P: 0.3199\n",
      "-155.08771929824562\n",
      "Episode: 58\n",
      "Reached the goal after 519 timesteps\n",
      "Episode: 58 Training loss: 14.2055 Explore P: 0.3088\n",
      "-159.63793103448276\n",
      "Episode: 59\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 59 Training loss: 8.3553 Explore P: 0.3085\n",
      "-155.40677966101694\n",
      "Episode: 60\n",
      "Reached the goal after 18 timesteps\n",
      "Episode: 60 Training loss: 14.9830 Explore P: 0.3081\n",
      "-151.45\n",
      "Episode: 61\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 61 Training loss: 9.5302 Explore P: 0.3080\n",
      "-147.44262295081967\n",
      "Episode: 62\n",
      "Reached the goal after 303 timesteps\n",
      "Episode: 62 Training loss: 17.1808 Explore P: 0.3017\n",
      "-148.33870967741936\n",
      "Episode: 63\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 63 Training loss: 14.4399 Explore P: 0.3014\n",
      "-144.66666666666666\n",
      "Episode: 64\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 64 Training loss: 12.1915 Explore P: 0.3012\n",
      "-140.953125\n",
      "Episode: 65\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 65 Training loss: 17.3791 Explore P: 0.3009\n",
      "-137.5076923076923\n",
      "Episode: 66\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 66 Training loss: 13.8451 Explore P: 0.3006\n",
      "-134.12121212121212\n",
      "Episode: 67\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 67 Training loss: 9.8214 Explore P: 0.3003\n",
      "-130.80597014925374\n",
      "Episode: 68\n",
      "Reached the goal after 450 timesteps\n",
      "Episode: 68 Training loss: 8.7227 Explore P: 0.2915\n",
      "-134.02941176470588\n",
      "Episode: 69\n",
      "Reached the goal after 19 timesteps\n",
      "Episode: 69 Training loss: 9.1006 Explore P: 0.2911\n",
      "-130.91304347826087\n",
      "Episode: 70\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 70 Training loss: 19.0213 Explore P: 0.2909\n",
      "-127.75714285714285\n",
      "Episode: 71\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 71 Training loss: 12.0503 Explore P: 0.2905\n",
      "-124.84507042253522\n",
      "Episode: 72\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 72 Training loss: 10.1239 Explore P: 0.2903\n",
      "-121.83333333333333\n",
      "Episode: 73\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 73 Training loss: 19.0601 Explore P: 0.2900\n",
      "-119.01369863013699\n",
      "Episode: 74\n",
      "Reached the goal after 967 timesteps\n",
      "Episode: 74 Training loss: 14.8271 Explore P: 0.2724\n",
      "-129.1216216216216\n",
      "Episode: 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 6 timesteps\n",
      "Episode: 75 Training loss: 15.4401 Explore P: 0.2723\n",
      "-126.14666666666666\n",
      "Episode: 76\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 76 Training loss: 16.2095 Explore P: 0.2721\n",
      "-123.34210526315789\n",
      "Episode: 77\n",
      "Reached the goal after 40 timesteps\n",
      "Episode: 77 Training loss: 17.2489 Explore P: 0.2714\n",
      "-120.96103896103897\n",
      "Episode: 78\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 78 Training loss: 17.3459 Explore P: 0.2712\n",
      "-118.26923076923077\n",
      "Episode: 79\n",
      "Reached the goal after 122 timesteps\n",
      "Episode: 79 Training loss: 19.7215 Explore P: 0.2691\n",
      "-117.0506329113924\n",
      "Episode: 80\n",
      "Reached the goal after 227 timesteps\n",
      "Episode: 80 Training loss: 17.3677 Explore P: 0.2653\n",
      "-117.175\n",
      "Episode: 81\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 81 Training loss: 21.4566 Explore P: 0.2652\n",
      "-114.54320987654322\n",
      "Episode: 82\n",
      "Reached the goal after 38 timesteps\n",
      "Episode: 82 Training loss: 15.8512 Explore P: 0.2645\n",
      "-112.39024390243902\n",
      "Episode: 83\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 83 Training loss: 19.6408 Explore P: 0.2644\n",
      "-109.89156626506023\n",
      "Episode: 84\n",
      "Reached the goal after 29 timesteps\n",
      "Episode: 84 Training loss: 14.8327 Explore P: 0.2639\n",
      "-107.73809523809524\n",
      "Episode: 85\n",
      "Reached the goal after 78 timesteps\n",
      "Episode: 85 Training loss: 10.8953 Explore P: 0.2626\n",
      "-106.21176470588236\n",
      "Episode: 86\n",
      "Reached the goal after 269 timesteps\n",
      "Episode: 86 Training loss: 16.9635 Explore P: 0.2583\n",
      "-106.94186046511628\n",
      "Episode: 87\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 87 Training loss: 18.1759 Explore P: 0.2582\n",
      "-104.62068965517241\n",
      "Episode: 88\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 88 Training loss: 18.7323 Explore P: 0.2580\n",
      "-102.4090909090909\n",
      "Episode: 89\n",
      "Reached the goal after 73 timesteps\n",
      "Episode: 89 Training loss: 16.2190 Explore P: 0.2569\n",
      "-100.95505617977528\n",
      "Episode: 90\n",
      "Reached the goal after 19 timesteps\n",
      "Episode: 90 Training loss: 16.9764 Explore P: 0.2566\n",
      "-98.93333333333334\n",
      "Episode: 91\n",
      "Reached the goal after 27 timesteps\n",
      "Episode: 91 Training loss: 16.4954 Explore P: 0.2561\n",
      "-97.04395604395604\n",
      "Episode: 92\n",
      "Reached the goal after 28 timesteps\n",
      "Episode: 92 Training loss: 18.9652 Explore P: 0.2557\n",
      "-95.20652173913044\n",
      "Episode: 93\n",
      "Reached the goal after 68 timesteps\n",
      "Episode: 93 Training loss: 14.0071 Explore P: 0.2546\n",
      "-93.83870967741936\n",
      "Episode: 94\n",
      "Reached the goal after 185 timesteps\n",
      "Episode: 94 Training loss: 17.6053 Explore P: 0.2518\n",
      "-93.74468085106383\n",
      "Episode: 95\n",
      "Reached the goal after 75 timesteps\n",
      "Episode: 95 Training loss: 13.1796 Explore P: 0.2506\n",
      "-92.49473684210527\n",
      "Episode: 96\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 96 Training loss: 18.3755 Explore P: 0.2505\n",
      "-90.55208333333333\n",
      "Episode: 97\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 97 Training loss: 26.3814 Explore P: 0.2503\n",
      "-88.69072164948453\n",
      "Episode: 98\n",
      "Reached the goal after 70 timesteps\n",
      "Episode: 98 Training loss: 15.2631 Explore P: 0.2493\n",
      "-87.4795918367347\n",
      "Episode: 99\n",
      "Reached the goal after 34 timesteps\n",
      "Episode: 99 Training loss: 15.6430 Explore P: 0.2488\n",
      "-85.92929292929293\n",
      "Episode: 100\n",
      "Reached the goal after 51 timesteps\n",
      "Episode: 100 Training loss: 19.5508 Explore P: 0.2480\n",
      "-84.58\n",
      "Episode: 101\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 101 Training loss: 9.1825 Explore P: 0.2478\n",
      "-82.89108910891089\n",
      "Episode: 102\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 102 Training loss: 14.3576 Explore P: 0.2476\n",
      "-81.22549019607843\n",
      "Episode: 103\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 103 Training loss: 15.7989 Explore P: 0.2474\n",
      "-79.55339805825243\n",
      "Episode: 104\n",
      "Reached the goal after 89 timesteps\n",
      "Episode: 104 Training loss: 22.4529 Explore P: 0.2461\n",
      "-78.6826923076923\n",
      "Episode: 105\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 105 Training loss: 24.3072 Explore P: 0.2460\n",
      "-77.02857142857142\n",
      "Episode: 106\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 106 Training loss: 15.7894 Explore P: 0.2459\n",
      "-75.43396226415095\n",
      "Episode: 107\n",
      "Reached the goal after 29 timesteps\n",
      "Episode: 107 Training loss: 15.9458 Explore P: 0.2454\n",
      "-74.06542056074767\n",
      "Episode: 108\n",
      "Reached the goal after 36 timesteps\n",
      "Episode: 108 Training loss: 16.0752 Explore P: 0.2449\n",
      "-72.78703703703704\n",
      "Episode: 109\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 109 Training loss: 29.9820 Explore P: 0.2447\n",
      "-71.29357798165138\n",
      "Episode: 110\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 110 Training loss: 13.6159 Explore P: 0.2446\n",
      "-69.80909090909091\n",
      "Episode: 111\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 111 Training loss: 18.6837 Explore P: 0.2445\n",
      "-68.34234234234235\n",
      "Episode: 112\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 112 Training loss: 21.8095 Explore P: 0.2444\n",
      "-66.89285714285714\n",
      "Episode: 113\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 113 Training loss: 15.1279 Explore P: 0.2442\n",
      "-65.51327433628319\n",
      "Episode: 114\n",
      "Reached the goal after 140 timesteps\n",
      "Episode: 114 Training loss: 18.8787 Explore P: 0.2422\n",
      "-65.28947368421052\n",
      "Episode: 115\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 115 Training loss: 17.6694 Explore P: 0.2420\n",
      "-63.95652173913044\n",
      "Episode: 116\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 116 Training loss: 21.3944 Explore P: 0.2418\n",
      "-62.64655172413793\n",
      "Episode: 117\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 117 Training loss: 21.6712 Explore P: 0.2417\n",
      "-61.31623931623932\n",
      "Episode: 118\n",
      "Reached the goal after 84 timesteps\n",
      "Episode: 118 Training loss: 18.1956 Explore P: 0.2405\n",
      "-60.66101694915254\n",
      "Episode: 119\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 119 Training loss: 12.5339 Explore P: 0.2404\n",
      "-59.36134453781513\n",
      "Episode: 120\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 120 Training loss: 25.2769 Explore P: 0.2403\n",
      "-58.1\n",
      "Episode: 121\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 121 Training loss: 20.6646 Explore P: 0.2402\n",
      "-56.84297520661157\n",
      "Episode: 122\n",
      "Reached the goal after 27 timesteps\n",
      "Episode: 122 Training loss: 17.8180 Explore P: 0.2398\n",
      "-55.778688524590166\n",
      "Episode: 123\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 123 Training loss: 23.0753 Explore P: 0.2396\n",
      "-54.60162601626016\n",
      "Episode: 124\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 124 Training loss: 22.7043 Explore P: 0.2395\n",
      "-53.41129032258065\n",
      "Episode: 125\n",
      "Reached the goal after 216 timesteps\n",
      "Episode: 125 Training loss: 32.3846 Explore P: 0.2365\n",
      "-53.912\n",
      "Episode: 126\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 126 Training loss: 20.0593 Explore P: 0.2365\n",
      "-52.72222222222222\n",
      "Episode: 127\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 127 Training loss: 23.1587 Explore P: 0.2364\n",
      "-51.56692913385827\n",
      "Episode: 128\n",
      "Reached the goal after 160 timesteps\n",
      "Episode: 128 Training loss: 24.3138 Explore P: 0.2342\n",
      "-51.6328125\n",
      "Episode: 129\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 129 Training loss: 17.7844 Explore P: 0.2340\n",
      "-50.542635658914726\n",
      "Episode: 130\n",
      "Reached the goal after 38 timesteps\n",
      "Episode: 130 Training loss: 17.0450 Explore P: 0.2335\n",
      "-49.676923076923075\n",
      "Episode: 131\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 131 Training loss: 24.4951 Explore P: 0.2334\n",
      "-48.58015267175573\n",
      "Episode: 132\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 132 Training loss: 29.4323 Explore P: 0.2333\n",
      "-47.515151515151516\n",
      "Episode: 133\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 133 Training loss: 16.9074 Explore P: 0.2332\n",
      "-46.43609022556391\n",
      "Episode: 134\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 134 Training loss: 19.3151 Explore P: 0.2329\n",
      "-45.53731343283582\n",
      "Episode: 135\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 135 Training loss: 21.2064 Explore P: 0.2326\n",
      "-44.60740740740741\n",
      "Episode: 136\n",
      "Reached the goal after 29 timesteps\n",
      "Episode: 136 Training loss: 28.7450 Explore P: 0.2322\n",
      "-43.75735294117647\n",
      "Episode: 137\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 137 Training loss: 19.5219 Explore P: 0.2320\n",
      "-42.7956204379562\n",
      "Episode: 138\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 138 Training loss: 25.5138 Explore P: 0.2319\n",
      "-41.833333333333336\n",
      "Episode: 139\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 139 Training loss: 18.0442 Explore P: 0.2317\n",
      "-40.89208633093525\n",
      "Episode: 140\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 140 Training loss: 25.2390 Explore P: 0.2315\n",
      "-40.00714285714286\n",
      "Episode: 141\n",
      "Reached the goal after 29 timesteps\n",
      "Episode: 141 Training loss: 24.6071 Explore P: 0.2311\n",
      "-39.219858156028366\n",
      "Episode: 142\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 142 Training loss: 31.8806 Explore P: 0.2307\n",
      "-38.42253521126761\n",
      "Episode: 143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 7 timesteps\n",
      "Episode: 143 Training loss: 25.7493 Explore P: 0.2306\n",
      "-37.50349650349651\n",
      "Episode: 144\n",
      "Reached the goal after 38 timesteps\n",
      "Episode: 144 Training loss: 32.2145 Explore P: 0.2301\n",
      "-36.8125\n",
      "Episode: 145\n",
      "Reached the goal after 24 timesteps\n",
      "Episode: 145 Training loss: 27.8022 Explore P: 0.2298\n",
      "-36.03448275862069\n",
      "Episode: 146\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 146 Training loss: 32.9518 Explore P: 0.2297\n",
      "-35.136986301369866\n",
      "Episode: 147\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 147 Training loss: 28.7637 Explore P: 0.2296\n",
      "-34.27210884353742\n",
      "Episode: 148\n",
      "Reached the goal after 89 timesteps\n",
      "Episode: 148 Training loss: 30.9712 Explore P: 0.2284\n",
      "-33.96621621621622\n",
      "Episode: 149\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 149 Training loss: 38.0990 Explore P: 0.2282\n",
      "-33.18120805369127\n",
      "Episode: 150\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 150 Training loss: 17.2922 Explore P: 0.2281\n",
      "-32.32666666666667\n",
      "Episode: 151\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 151 Training loss: 36.2502 Explore P: 0.2280\n",
      "-31.496688741721854\n",
      "Episode: 152\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 152 Training loss: 35.5786 Explore P: 0.2278\n",
      "-30.723684210526315\n",
      "Episode: 153\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 153 Training loss: 28.7940 Explore P: 0.2277\n",
      "-29.934640522875817\n",
      "Episode: 154\n",
      "Reached the goal after 23 timesteps\n",
      "Episode: 154 Training loss: 32.2259 Explore P: 0.2274\n",
      "-29.24025974025974\n",
      "Episode: 155\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 155 Training loss: 33.8880 Explore P: 0.2273\n",
      "-28.46451612903226\n",
      "Episode: 156\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 156 Training loss: 27.0378 Explore P: 0.2272\n",
      "-27.685897435897434\n",
      "Episode: 157\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 157 Training loss: 31.5445 Explore P: 0.2269\n",
      "-27.0\n",
      "Episode: 158\n",
      "Reached the goal after 2 timesteps\n",
      "Episode: 158 Training loss: 37.1585 Explore P: 0.2268\n",
      "-26.20886075949367\n",
      "Episode: 159\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 159 Training loss: 31.7704 Explore P: 0.2267\n",
      "-25.471698113207548\n",
      "Episode: 160\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 160 Training loss: 31.0217 Explore P: 0.2266\n",
      "-24.7375\n",
      "Episode: 161\n",
      "Reached the goal after 174 timesteps\n",
      "Episode: 161 Training loss: 38.6873 Explore P: 0.2244\n",
      "-25.043478260869566\n",
      "Episode: 162\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 162 Training loss: 38.0259 Explore P: 0.2243\n",
      "-24.32716049382716\n",
      "Episode: 163\n",
      "Reached the goal after 70 timesteps\n",
      "Episode: 163 Training loss: 40.2716 Explore P: 0.2234\n",
      "-23.993865030674847\n",
      "Episode: 164\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 164 Training loss: 38.3082 Explore P: 0.2233\n",
      "-23.28048780487805\n",
      "Episode: 165\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 165 Training loss: 31.5342 Explore P: 0.2232\n",
      "-22.56969696969697\n",
      "Episode: 166\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 166 Training loss: 32.9845 Explore P: 0.2231\n",
      "-21.879518072289155\n",
      "Episode: 167\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 167 Training loss: 35.5611 Explore P: 0.2230\n",
      "-21.209580838323355\n",
      "Episode: 168\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 168 Training loss: 36.9715 Explore P: 0.2228\n",
      "-20.56547619047619\n",
      "Episode: 169\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 169 Training loss: 36.9886 Explore P: 0.2227\n",
      "-19.88757396449704\n",
      "Episode: 170\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 170 Training loss: 32.6783 Explore P: 0.2226\n",
      "-19.229411764705883\n",
      "Episode: 171\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 171 Training loss: 39.0271 Explore P: 0.2223\n",
      "-18.65497076023392\n",
      "Episode: 172\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 172 Training loss: 39.5155 Explore P: 0.2222\n",
      "-18.023255813953487\n",
      "Episode: 173\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 173 Training loss: 31.4066 Explore P: 0.2220\n",
      "-17.439306358381504\n",
      "Episode: 174\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 174 Training loss: 45.5194 Explore P: 0.2218\n",
      "-16.844827586206897\n",
      "Episode: 175\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 175 Training loss: 35.9460 Explore P: 0.2216\n",
      "-16.257142857142856\n",
      "Episode: 176\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 176 Training loss: 41.6868 Explore P: 0.2215\n",
      "-15.664772727272727\n",
      "Episode: 177\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 177 Training loss: 46.6322 Explore P: 0.2214\n",
      "-15.045197740112995\n",
      "Episode: 178\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 178 Training loss: 30.6811 Explore P: 0.2213\n",
      "-14.426966292134832\n",
      "Episode: 179\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 179 Training loss: 45.8484 Explore P: 0.2212\n",
      "-13.849162011173185\n",
      "Episode: 180\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 180 Training loss: 36.4676 Explore P: 0.2211\n",
      "-13.238888888888889\n",
      "Episode: 181\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 181 Training loss: 38.7232 Explore P: 0.2210\n",
      "-12.657458563535911\n",
      "Episode: 182\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 182 Training loss: 43.7690 Explore P: 0.2208\n",
      "-12.098901098901099\n",
      "Episode: 183\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 183 Training loss: 45.5072 Explore P: 0.2207\n",
      "-11.546448087431694\n",
      "Episode: 184\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 184 Training loss: 34.6146 Explore P: 0.2206\n",
      "-10.96195652173913\n",
      "Episode: 185\n",
      "Reached the goal after 52 timesteps\n",
      "Episode: 185 Training loss: 35.5148 Explore P: 0.2200\n",
      "-10.643243243243242\n",
      "Episode: 186\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 186 Training loss: 47.3921 Explore P: 0.2199\n",
      "-10.091397849462366\n",
      "Episode: 187\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 187 Training loss: 38.3476 Explore P: 0.2198\n",
      "-9.550802139037433\n",
      "Episode: 188\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 188 Training loss: 31.5770 Explore P: 0.2196\n",
      "-9.053191489361701\n",
      "Episode: 189\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 189 Training loss: 38.3140 Explore P: 0.2194\n",
      "-8.56084656084656\n",
      "Episode: 190\n",
      "Reached the goal after 59 timesteps\n",
      "Episode: 190 Training loss: 30.2658 Explore P: 0.2187\n",
      "-8.3\n",
      "Episode: 191\n",
      "Reached the goal after 30 timesteps\n",
      "Episode: 191 Training loss: 38.5072 Explore P: 0.2183\n",
      "-7.890052356020942\n",
      "Episode: 192\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 192 Training loss: 51.7777 Explore P: 0.2182\n",
      "-7.354166666666667\n",
      "Episode: 193\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 193 Training loss: 35.5664 Explore P: 0.2181\n",
      "-6.83419689119171\n",
      "Episode: 194\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 194 Training loss: 50.7073 Explore P: 0.2181\n",
      "-6.304123711340206\n",
      "Episode: 195\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 195 Training loss: 38.5711 Explore P: 0.2177\n",
      "-5.892307692307693\n",
      "Episode: 196\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 196 Training loss: 41.1795 Explore P: 0.2176\n",
      "-5.3979591836734695\n",
      "Episode: 197\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 197 Training loss: 37.2308 Explore P: 0.2175\n",
      "-4.898477157360406\n",
      "Episode: 198\n",
      "Reached the goal after 31 timesteps\n",
      "Episode: 198 Training loss: 41.5297 Explore P: 0.2172\n",
      "-4.525252525252525\n",
      "Episode: 199\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 199 Training loss: 33.5467 Explore P: 0.2171\n",
      "-4.030150753768845\n",
      "Episode: 200\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 200 Training loss: 34.0400 Explore P: 0.2170\n",
      "-3.545\n",
      "Episode: 201\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 201 Training loss: 36.5879 Explore P: 0.2169\n",
      "-3.0696517412935322\n",
      "Episode: 202\n",
      "Reached the goal after 35 timesteps\n",
      "Episode: 202 Training loss: 35.7587 Explore P: 0.2165\n",
      "-2.732673267326733\n",
      "Episode: 203\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 203 Training loss: 43.9285 Explore P: 0.2163\n",
      "-2.2758620689655173\n",
      "Episode: 204\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 204 Training loss: 37.1394 Explore P: 0.2162\n",
      "-1.838235294117647\n",
      "Episode: 205\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 205 Training loss: 39.2193 Explore P: 0.2161\n",
      "-1.3804878048780487\n",
      "Episode: 206\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 206 Training loss: 45.7845 Explore P: 0.2159\n",
      "-0.9320388349514563\n",
      "Episode: 207\n",
      "Reached the goal after 45 timesteps\n",
      "Episode: 207 Training loss: 44.4871 Explore P: 0.2154\n",
      "-0.6618357487922706\n",
      "Episode: 208\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 208 Training loss: 49.4130 Explore P: 0.2153\n",
      "-0.22596153846153846\n",
      "Episode: 209\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 209 Training loss: 43.1453 Explore P: 0.2151\n",
      "0.18181818181818182\n",
      "Episode: 210\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 210 Training loss: 36.9683 Explore P: 0.2150\n",
      "0.6285714285714286\n",
      "Episode: 211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 27 timesteps\n",
      "Episode: 211 Training loss: 56.3094 Explore P: 0.2147\n",
      "0.9715639810426541\n",
      "Episode: 212\n",
      "Reached the goal after 471 timesteps\n",
      "Episode: 212 Training loss: 50.9281 Explore P: 0.2094\n",
      "-0.7830188679245284\n",
      "Episode: 213\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 213 Training loss: 40.1308 Explore P: 0.2092\n",
      "-0.38497652582159625\n",
      "Episode: 214\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 214 Training loss: 47.7834 Explore P: 0.2091\n",
      "0.056074766355140186\n",
      "Episode: 215\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 215 Training loss: 43.1358 Explore P: 0.2091\n",
      "0.5069767441860465\n",
      "Episode: 216\n",
      "Reached the goal after 116 timesteps\n",
      "Episode: 216 Training loss: 62.0441 Explore P: 0.2078\n",
      "0.4305555555555556\n",
      "Episode: 217\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 217 Training loss: 42.9841 Explore P: 0.2078\n",
      "0.8709677419354839\n",
      "Episode: 218\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 218 Training loss: 43.3583 Explore P: 0.2076\n",
      "1.2522935779816513\n",
      "Episode: 219\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 219 Training loss: 34.5496 Explore P: 0.2074\n",
      "1.6118721461187215\n",
      "Episode: 220\n",
      "Reached the goal after 18 timesteps\n",
      "Episode: 220 Training loss: 43.5408 Explore P: 0.2072\n",
      "1.9772727272727273\n",
      "Episode: 221\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 221 Training loss: 49.6107 Explore P: 0.2070\n",
      "2.3755656108597285\n",
      "Episode: 222\n",
      "Reached the goal after 33 timesteps\n",
      "Episode: 222 Training loss: 58.2907 Explore P: 0.2067\n",
      "2.6666666666666665\n",
      "Episode: 223\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 223 Training loss: 47.6077 Explore P: 0.2066\n",
      "3.0582959641255605\n",
      "Episode: 224\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 224 Training loss: 40.7918 Explore P: 0.2065\n",
      "3.4598214285714284\n",
      "Episode: 225\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 225 Training loss: 49.7776 Explore P: 0.2063\n",
      "3.8222222222222224\n",
      "Episode: 226\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 226 Training loss: 49.4383 Explore P: 0.2062\n",
      "4.212389380530974\n",
      "Episode: 227\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 227 Training loss: 47.3019 Explore P: 0.2061\n",
      "4.581497797356828\n",
      "Episode: 228\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 228 Training loss: 37.4111 Explore P: 0.2058\n",
      "4.907894736842105\n",
      "Episode: 229\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 229 Training loss: 43.0095 Explore P: 0.2057\n",
      "5.262008733624454\n",
      "Episode: 230\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 230 Training loss: 56.6642 Explore P: 0.2056\n",
      "5.621739130434783\n",
      "Episode: 231\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 231 Training loss: 50.6348 Explore P: 0.2054\n",
      "5.956709956709957\n",
      "Episode: 232\n",
      "Reached the goal after 2 timesteps\n",
      "Episode: 232 Training loss: 35.8070 Explore P: 0.2053\n",
      "6.353448275862069\n",
      "Episode: 233\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 233 Training loss: 48.4972 Explore P: 0.2052\n",
      "6.71244635193133\n",
      "Episode: 234\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 234 Training loss: 61.9048 Explore P: 0.2052\n",
      "7.098290598290598\n",
      "Episode: 235\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 235 Training loss: 38.0879 Explore P: 0.2051\n",
      "7.451063829787234\n",
      "Episode: 236\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 236 Training loss: 40.1324 Explore P: 0.2050\n",
      "7.813559322033898\n",
      "Episode: 237\n",
      "Reached the goal after 19 timesteps\n",
      "Episode: 237 Training loss: 62.3675 Explore P: 0.2048\n",
      "8.122362869198312\n",
      "Episode: 238\n",
      "Reached the goal after 25 timesteps\n",
      "Episode: 238 Training loss: 41.1368 Explore P: 0.2045\n",
      "8.403361344537815\n",
      "Episode: 239\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 239 Training loss: 41.5396 Explore P: 0.2044\n",
      "8.753138075313808\n",
      "Episode: 240\n",
      "Reached the goal after 71 timesteps\n",
      "Episode: 240 Training loss: 53.3941 Explore P: 0.2036\n",
      "8.8375\n",
      "Episode: 241\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 241 Training loss: 55.2700 Explore P: 0.2036\n",
      "9.186721991701244\n",
      "Episode: 242\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 242 Training loss: 43.9903 Explore P: 0.2035\n",
      "9.53305785123967\n",
      "Episode: 243\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 243 Training loss: 46.6501 Explore P: 0.2034\n",
      "9.868312757201647\n",
      "Episode: 244\n",
      "Reached the goal after 22 timesteps\n",
      "Episode: 244 Training loss: 41.4663 Explore P: 0.2031\n",
      "10.147540983606557\n",
      "Episode: 245\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 245 Training loss: 60.3361 Explore P: 0.2031\n",
      "10.489795918367347\n",
      "Episode: 246\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 246 Training loss: 35.6064 Explore P: 0.2030\n",
      "10.833333333333334\n",
      "Episode: 247\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 247 Training loss: 56.8267 Explore P: 0.2029\n",
      "11.145748987854251\n",
      "Episode: 248\n",
      "Reached the goal after 29 timesteps\n",
      "Episode: 248 Training loss: 49.3910 Explore P: 0.2026\n",
      "11.387096774193548\n",
      "Episode: 249\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 249 Training loss: 47.8535 Explore P: 0.2025\n",
      "11.718875502008032\n",
      "Episode: 250\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 250 Training loss: 56.4055 Explore P: 0.2024\n",
      "12.048\n",
      "Episode: 251\n",
      "Reached the goal after 27 timesteps\n",
      "Episode: 251 Training loss: 52.8683 Explore P: 0.2021\n",
      "12.290836653386455\n",
      "Episode: 252\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 252 Training loss: 43.3637 Explore P: 0.2020\n",
      "12.59920634920635\n",
      "Episode: 253\n",
      "Reached the goal after 24 timesteps\n",
      "Episode: 253 Training loss: 49.5750 Explore P: 0.2018\n",
      "12.849802371541502\n",
      "Episode: 254\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 254 Training loss: 54.8668 Explore P: 0.2017\n",
      "13.17716535433071\n",
      "Episode: 255\n",
      "Reached the goal after 18 timesteps\n",
      "Episode: 255 Training loss: 44.9123 Explore P: 0.2015\n",
      "13.447058823529412\n",
      "Episode: 256\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 256 Training loss: 64.4777 Explore P: 0.2014\n",
      "13.75390625\n",
      "Episode: 257\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 257 Training loss: 55.0097 Explore P: 0.2012\n",
      "14.007782101167315\n",
      "Episode: 258\n",
      "Reached the goal after 23 timesteps\n",
      "Episode: 258 Training loss: 55.2162 Explore P: 0.2010\n",
      "14.251937984496124\n",
      "Episode: 259\n",
      "Reached the goal after 64 timesteps\n",
      "Episode: 259 Training loss: 52.7514 Explore P: 0.2003\n",
      "14.335907335907336\n",
      "Episode: 260\n",
      "Reached the goal after 123 timesteps\n",
      "Episode: 260 Training loss: 53.6788 Explore P: 0.1991\n",
      "14.192307692307692\n",
      "Episode: 261\n",
      "Reached the goal after 22 timesteps\n",
      "Episode: 261 Training loss: 68.7734 Explore P: 0.1988\n",
      "14.436781609195402\n",
      "Episode: 262\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 262 Training loss: 53.7018 Explore P: 0.1988\n",
      "14.740458015267176\n",
      "Episode: 263\n",
      "Reached the goal after 90 timesteps\n",
      "Episode: 263 Training loss: 54.0669 Explore P: 0.1979\n",
      "14.722433460076045\n",
      "Episode: 264\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 264 Training loss: 59.9837 Explore P: 0.1978\n",
      "15.022727272727273\n",
      "Episode: 265\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 265 Training loss: 45.9176 Explore P: 0.1977\n",
      "15.30188679245283\n",
      "Episode: 266\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 266 Training loss: 49.4092 Explore P: 0.1976\n",
      "15.601503759398497\n",
      "Episode: 267\n",
      "Reached the goal after 68 timesteps\n",
      "Episode: 267 Training loss: 63.8261 Explore P: 0.1970\n",
      "15.662921348314606\n",
      "Episode: 268\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 268 Training loss: 48.9498 Explore P: 0.1969\n",
      "15.940298507462687\n",
      "Episode: 269\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 269 Training loss: 48.4960 Explore P: 0.1967\n",
      "16.197026022304833\n",
      "Episode: 270\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 270 Training loss: 71.3115 Explore P: 0.1966\n",
      "16.488888888888887\n",
      "Episode: 271\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 271 Training loss: 49.9848 Explore P: 0.1965\n",
      "16.760147601476014\n",
      "Episode: 272\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 272 Training loss: 66.0918 Explore P: 0.1964\n",
      "17.033088235294116\n",
      "Episode: 273\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 273 Training loss: 64.7421 Explore P: 0.1964\n",
      "17.315018315018314\n",
      "Episode: 274\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 274 Training loss: 60.0013 Explore P: 0.1963\n",
      "17.572992700729927\n",
      "Episode: 275\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 275 Training loss: 45.3622 Explore P: 0.1961\n",
      "17.832727272727272\n",
      "Episode: 276\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 276 Training loss: 69.3977 Explore P: 0.1960\n",
      "18.07246376811594\n",
      "Episode: 277\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 277 Training loss: 63.2801 Explore P: 0.1959\n",
      "18.350180505415164\n",
      "Episode: 278\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 278 Training loss: 57.1264 Explore P: 0.1958\n",
      "18.593525179856115\n",
      "Episode: 279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 6 timesteps\n",
      "Episode: 279 Training loss: 56.0723 Explore P: 0.1957\n",
      "18.863799283154123\n",
      "Episode: 280\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 280 Training loss: 54.6145 Explore P: 0.1956\n",
      "19.12142857142857\n",
      "Episode: 281\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 281 Training loss: 61.6400 Explore P: 0.1955\n",
      "19.366548042704625\n",
      "Episode: 282\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 282 Training loss: 68.8534 Explore P: 0.1954\n",
      "19.613475177304963\n",
      "Episode: 283\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 283 Training loss: 55.9532 Explore P: 0.1953\n",
      "19.879858657243815\n",
      "Episode: 284\n",
      "Reached the goal after 19 timesteps\n",
      "Episode: 284 Training loss: 60.0565 Explore P: 0.1951\n",
      "20.095070422535212\n",
      "Episode: 285\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 285 Training loss: 47.4895 Explore P: 0.1951\n",
      "20.357894736842105\n",
      "Episode: 286\n",
      "Reached the goal after 22 timesteps\n",
      "Episode: 286 Training loss: 52.2343 Explore P: 0.1948\n",
      "20.55944055944056\n",
      "Episode: 287\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 287 Training loss: 50.9575 Explore P: 0.1948\n",
      "20.81533101045296\n",
      "Episode: 288\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 288 Training loss: 58.9882 Explore P: 0.1947\n",
      "21.0625\n",
      "Episode: 289\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 289 Training loss: 64.9179 Explore P: 0.1946\n",
      "21.301038062283737\n",
      "Episode: 290\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 290 Training loss: 53.1873 Explore P: 0.1945\n",
      "21.541379310344826\n",
      "Episode: 291\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 291 Training loss: 57.1406 Explore P: 0.1944\n",
      "21.790378006872853\n",
      "Episode: 292\n",
      "Reached the goal after 41 timesteps\n",
      "Episode: 292 Training loss: 73.9259 Explore P: 0.1940\n",
      "21.91780821917808\n",
      "Episode: 293\n",
      "Reached the goal after 2 timesteps\n",
      "Episode: 293 Training loss: 71.1206 Explore P: 0.1940\n",
      "22.177474402730375\n",
      "Episode: 294\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 294 Training loss: 62.7833 Explore P: 0.1939\n",
      "22.41496598639456\n",
      "Episode: 295\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 295 Training loss: 62.7636 Explore P: 0.1937\n",
      "22.589830508474577\n",
      "Episode: 296\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 296 Training loss: 59.9651 Explore P: 0.1936\n",
      "22.824324324324323\n",
      "Episode: 297\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 297 Training loss: 60.7361 Explore P: 0.1935\n",
      "23.04040404040404\n",
      "Episode: 298\n",
      "Reached the goal after 68 timesteps\n",
      "Episode: 298 Training loss: 65.0568 Explore P: 0.1928\n",
      "23.07046979865772\n",
      "Episode: 299\n",
      "Reached the goal after 323 timesteps\n",
      "Episode: 299 Training loss: 54.3256 Explore P: 0.1899\n",
      "22.247491638795985\n",
      "Episode: 300\n",
      "Reached the goal after 30 timesteps\n",
      "Episode: 300 Training loss: 48.3567 Explore P: 0.1896\n",
      "22.406666666666666\n",
      "Episode: 301\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 301 Training loss: 64.4442 Explore P: 0.1895\n",
      "22.64451827242525\n",
      "Episode: 302\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 302 Training loss: 62.4446 Explore P: 0.1893\n",
      "22.834437086092716\n",
      "Episode: 303\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 303 Training loss: 54.1182 Explore P: 0.1892\n",
      "23.046204620462046\n",
      "Episode: 304\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 304 Training loss: 76.2061 Explore P: 0.1891\n",
      "23.263157894736842\n",
      "Episode: 305\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 305 Training loss: 49.3021 Explore P: 0.1890\n",
      "23.485245901639345\n",
      "Episode: 306\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 306 Training loss: 59.4579 Explore P: 0.1890\n",
      "23.72222222222222\n",
      "Episode: 307\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 307 Training loss: 64.1653 Explore P: 0.1889\n",
      "23.938110749185668\n",
      "Episode: 308\n",
      "Reached the goal after 47 timesteps\n",
      "Episode: 308 Training loss: 64.1153 Explore P: 0.1884\n",
      "24.032467532467532\n",
      "Episode: 309\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 309 Training loss: 59.6438 Explore P: 0.1883\n",
      "24.22653721682848\n",
      "Episode: 310\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 310 Training loss: 59.8871 Explore P: 0.1882\n",
      "24.44516129032258\n",
      "Episode: 311\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 311 Training loss: 57.6423 Explore P: 0.1880\n",
      "24.633440514469452\n",
      "Episode: 312\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 312 Training loss: 64.3764 Explore P: 0.1880\n",
      "24.84294871794872\n",
      "Episode: 313\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 313 Training loss: 57.2870 Explore P: 0.1879\n",
      "25.054313099041533\n",
      "Episode: 314\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 314 Training loss: 66.5790 Explore P: 0.1878\n",
      "25.273885350318473\n",
      "Episode: 315\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 315 Training loss: 56.2252 Explore P: 0.1877\n",
      "25.488888888888887\n",
      "Episode: 316\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 316 Training loss: 68.4832 Explore P: 0.1877\n",
      "25.70253164556962\n",
      "Episode: 317\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 317 Training loss: 66.9730 Explore P: 0.1876\n",
      "25.91167192429022\n",
      "Episode: 318\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 318 Training loss: 73.1745 Explore P: 0.1875\n",
      "26.11006289308176\n",
      "Episode: 319\n",
      "Reached the goal after 39 timesteps\n",
      "Episode: 319 Training loss: 72.2843 Explore P: 0.1871\n",
      "26.219435736677116\n",
      "Episode: 320\n",
      "Reached the goal after 52 timesteps\n",
      "Episode: 320 Training loss: 51.5672 Explore P: 0.1867\n",
      "26.2875\n",
      "Episode: 321\n",
      "Reached the goal after 34 timesteps\n",
      "Episode: 321 Training loss: 68.8880 Explore P: 0.1864\n",
      "26.411214953271028\n",
      "Episode: 322\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 322 Training loss: 63.2228 Explore P: 0.1863\n",
      "26.624223602484474\n",
      "Episode: 323\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 323 Training loss: 61.0413 Explore P: 0.1862\n",
      "26.8297213622291\n",
      "Episode: 324\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 324 Training loss: 61.6707 Explore P: 0.1861\n",
      "27.012345679012345\n",
      "Episode: 325\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 325 Training loss: 63.6714 Explore P: 0.1860\n",
      "27.215384615384615\n",
      "Episode: 326\n",
      "Reached the goal after 203 timesteps\n",
      "Episode: 326 Training loss: 60.5526 Explore P: 0.1843\n",
      "26.8159509202454\n",
      "Episode: 327\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 327 Training loss: 58.7691 Explore P: 0.1842\n",
      "27.015290519877677\n",
      "Episode: 328\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 328 Training loss: 75.4085 Explore P: 0.1841\n",
      "27.204268292682926\n",
      "Episode: 329\n",
      "Reached the goal after 77 timesteps\n",
      "Episode: 329 Training loss: 77.4775 Explore P: 0.1835\n",
      "27.19148936170213\n",
      "Episode: 330\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 330 Training loss: 70.0596 Explore P: 0.1834\n",
      "27.37272727272727\n",
      "Episode: 331\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 331 Training loss: 62.1141 Explore P: 0.1832\n",
      "27.52870090634441\n",
      "Episode: 332\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 332 Training loss: 79.5864 Explore P: 0.1831\n",
      "27.710843373493976\n",
      "Episode: 333\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 333 Training loss: 79.2451 Explore P: 0.1830\n",
      "27.9009009009009\n",
      "Episode: 334\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 334 Training loss: 62.9413 Explore P: 0.1829\n",
      "28.092814371257486\n",
      "Episode: 335\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 335 Training loss: 72.9194 Explore P: 0.1828\n",
      "28.286567164179104\n",
      "Episode: 336\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 336 Training loss: 55.8458 Explore P: 0.1828\n",
      "28.482142857142858\n",
      "Episode: 337\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 337 Training loss: 67.5438 Explore P: 0.1827\n",
      "28.670623145400594\n",
      "Episode: 338\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 338 Training loss: 62.2593 Explore P: 0.1826\n",
      "28.857988165680474\n",
      "Episode: 339\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 339 Training loss: 64.2243 Explore P: 0.1826\n",
      "29.04424778761062\n",
      "Episode: 340\n",
      "Reached the goal after 211 timesteps\n",
      "Episode: 340 Training loss: 74.5206 Explore P: 0.1808\n",
      "28.63235294117647\n",
      "Episode: 341\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 341 Training loss: 76.6015 Explore P: 0.1808\n",
      "28.818181818181817\n",
      "Episode: 342\n",
      "Reached the goal after 28 timesteps\n",
      "Episode: 342 Training loss: 70.7216 Explore P: 0.1805\n",
      "28.944444444444443\n",
      "Episode: 343\n",
      "Reached the goal after 111 timesteps\n",
      "Episode: 343 Training loss: 73.9099 Explore P: 0.1796\n",
      "28.82798833819242\n",
      "Episode: 344\n",
      "Reached the goal after 56 timesteps\n",
      "Episode: 344 Training loss: 62.2954 Explore P: 0.1792\n",
      "28.872093023255815\n",
      "Episode: 345\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 345 Training loss: 74.5411 Explore P: 0.1791\n",
      "29.046376811594204\n",
      "Episode: 346\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 346 Training loss: 74.5218 Explore P: 0.1790\n",
      "29.22543352601156\n",
      "Episode: 347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 4 timesteps\n",
      "Episode: 347 Training loss: 66.6437 Explore P: 0.1790\n",
      "29.417867435158502\n",
      "Episode: 348\n",
      "Reached the goal after 59 timesteps\n",
      "Episode: 348 Training loss: 65.5817 Explore P: 0.1785\n",
      "29.451149425287355\n",
      "Episode: 349\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 349 Training loss: 61.4224 Explore P: 0.1783\n",
      "29.578796561604584\n",
      "Episode: 350\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 350 Training loss: 68.7294 Explore P: 0.1782\n",
      "29.751428571428573\n",
      "Episode: 351\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 351 Training loss: 63.8039 Explore P: 0.1781\n",
      "29.934472934472936\n",
      "Episode: 352\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 352 Training loss: 75.8442 Explore P: 0.1780\n",
      "30.099431818181817\n",
      "Episode: 353\n",
      "Reached the goal after 25 timesteps\n",
      "Episode: 353 Training loss: 81.8934 Explore P: 0.1778\n",
      "30.226628895184135\n",
      "Episode: 354\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 354 Training loss: 68.9603 Explore P: 0.1777\n",
      "30.387005649717516\n",
      "Episode: 355\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 355 Training loss: 66.4120 Explore P: 0.1776\n",
      "30.55211267605634\n",
      "Episode: 356\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 356 Training loss: 73.9480 Explore P: 0.1776\n",
      "30.735955056179776\n",
      "Episode: 357\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 357 Training loss: 68.5940 Explore P: 0.1775\n",
      "30.910364145658264\n",
      "Episode: 358\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 358 Training loss: 64.0956 Explore P: 0.1775\n",
      "31.08100558659218\n",
      "Episode: 359\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 359 Training loss: 69.3817 Explore P: 0.1774\n",
      "31.25348189415042\n",
      "Episode: 360\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 360 Training loss: 72.1368 Explore P: 0.1773\n",
      "31.419444444444444\n",
      "Episode: 361\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 361 Training loss: 70.7090 Explore P: 0.1772\n",
      "31.58448753462604\n",
      "Episode: 362\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 362 Training loss: 64.1572 Explore P: 0.1772\n",
      "31.751381215469614\n",
      "Episode: 363\n",
      "Reached the goal after 55 timesteps\n",
      "Episode: 363 Training loss: 85.1406 Explore P: 0.1767\n",
      "31.78787878787879\n",
      "Episode: 364\n",
      "Reached the goal after 37 timesteps\n",
      "Episode: 364 Training loss: 61.2883 Explore P: 0.1765\n",
      "31.873626373626372\n",
      "Episode: 365\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 365 Training loss: 75.5700 Explore P: 0.1764\n",
      "32.032876712328765\n",
      "Episode: 366\n",
      "Reached the goal after 35 timesteps\n",
      "Episode: 366 Training loss: 65.3423 Explore P: 0.1761\n",
      "32.122950819672134\n",
      "Episode: 367\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 367 Training loss: 78.7735 Explore P: 0.1760\n",
      "32.29155313351499\n",
      "Episode: 368\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 368 Training loss: 71.4091 Explore P: 0.1760\n",
      "32.46467391304348\n",
      "Episode: 369\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 369 Training loss: 82.9446 Explore P: 0.1759\n",
      "32.62872628726287\n",
      "Episode: 370\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 370 Training loss: 70.9594 Explore P: 0.1759\n",
      "32.8\n",
      "Episode: 371\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 371 Training loss: 75.3164 Explore P: 0.1758\n",
      "32.9622641509434\n",
      "Episode: 372\n",
      "Reached the goal after 23 timesteps\n",
      "Episode: 372 Training loss: 60.7768 Explore P: 0.1757\n",
      "33.08064516129032\n",
      "Episode: 373\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 373 Training loss: 64.1325 Explore P: 0.1756\n",
      "33.24396782841823\n",
      "Episode: 374\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 374 Training loss: 67.8755 Explore P: 0.1756\n",
      "33.403743315508024\n",
      "Episode: 375\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 375 Training loss: 66.0709 Explore P: 0.1755\n",
      "33.565333333333335\n",
      "Episode: 376\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 376 Training loss: 67.7456 Explore P: 0.1754\n",
      "33.71808510638298\n",
      "Episode: 377\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 377 Training loss: 63.0843 Explore P: 0.1754\n",
      "33.87798408488064\n",
      "Episode: 378\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 378 Training loss: 76.5887 Explore P: 0.1753\n",
      "34.03703703703704\n",
      "Episode: 379\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 379 Training loss: 80.7936 Explore P: 0.1753\n",
      "34.19788918205805\n",
      "Episode: 380\n",
      "Reached the goal after 35 timesteps\n",
      "Episode: 380 Training loss: 89.3408 Explore P: 0.1750\n",
      "34.27894736842105\n",
      "Episode: 381\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 381 Training loss: 76.6548 Explore P: 0.1749\n",
      "34.43569553805774\n",
      "Episode: 382\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 382 Training loss: 56.5016 Explore P: 0.1749\n",
      "34.583769633507856\n",
      "Episode: 383\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 383 Training loss: 67.0381 Explore P: 0.1748\n",
      "34.718015665796344\n",
      "Episode: 384\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 384 Training loss: 71.4970 Explore P: 0.1747\n",
      "34.877604166666664\n",
      "Episode: 385\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 385 Training loss: 83.2525 Explore P: 0.1747\n",
      "35.02597402597402\n",
      "Episode: 386\n",
      "Reached the goal after 42 timesteps\n",
      "Episode: 386 Training loss: 82.6875 Explore P: 0.1743\n",
      "35.08549222797927\n",
      "Episode: 387\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 387 Training loss: 59.5772 Explore P: 0.1742\n",
      "35.21963824289406\n",
      "Episode: 388\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 388 Training loss: 83.0552 Explore P: 0.1742\n",
      "35.368556701030926\n",
      "Episode: 389\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 389 Training loss: 70.3898 Explore P: 0.1741\n",
      "35.51413881748072\n",
      "Episode: 390\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 390 Training loss: 68.4810 Explore P: 0.1741\n",
      "35.666666666666664\n",
      "Episode: 391\n",
      "Reached the goal after 39 timesteps\n",
      "Episode: 391 Training loss: 92.6455 Explore P: 0.1738\n",
      "35.73145780051151\n",
      "Episode: 392\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 392 Training loss: 73.4303 Explore P: 0.1737\n",
      "35.87244897959184\n",
      "Episode: 393\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 393 Training loss: 84.8835 Explore P: 0.1736\n",
      "36.020356234096695\n",
      "Episode: 394\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 394 Training loss: 67.1037 Explore P: 0.1736\n",
      "36.15989847715736\n",
      "Episode: 395\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 395 Training loss: 88.8503 Explore P: 0.1735\n",
      "36.30126582278481\n",
      "Episode: 396\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 396 Training loss: 77.8266 Explore P: 0.1734\n",
      "36.43434343434343\n",
      "Episode: 397\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 397 Training loss: 66.4419 Explore P: 0.1733\n",
      "36.541561712846345\n",
      "Episode: 398\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 398 Training loss: 69.3391 Explore P: 0.1732\n",
      "36.688442211055275\n",
      "Episode: 399\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 399 Training loss: 62.3295 Explore P: 0.1731\n",
      "36.81954887218045\n",
      "Episode: 400\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 400 Training loss: 72.3809 Explore P: 0.1730\n",
      "36.9525\n",
      "Episode: 401\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 401 Training loss: 61.3741 Explore P: 0.1729\n",
      "37.072319201995015\n",
      "Episode: 402\n",
      "Reached the goal after 67 timesteps\n",
      "Episode: 402 Training loss: 70.6571 Explore P: 0.1724\n",
      "37.06218905472637\n",
      "Episode: 403\n",
      "Reached the goal after 81 timesteps\n",
      "Episode: 403 Training loss: 77.4606 Explore P: 0.1718\n",
      "37.01736972704715\n",
      "Episode: 404\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 404 Training loss: 79.4138 Explore P: 0.1717\n",
      "37.14356435643565\n",
      "Episode: 405\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 405 Training loss: 70.9511 Explore P: 0.1717\n",
      "37.28641975308642\n",
      "Episode: 406\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 406 Training loss: 75.7800 Explore P: 0.1716\n",
      "37.41379310344828\n",
      "Episode: 407\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 407 Training loss: 67.4879 Explore P: 0.1716\n",
      "37.55036855036855\n",
      "Episode: 408\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 408 Training loss: 73.2171 Explore P: 0.1715\n",
      "37.69117647058823\n",
      "Episode: 409\n",
      "Reached the goal after 2 timesteps\n",
      "Episode: 409 Training loss: 69.0067 Explore P: 0.1715\n",
      "37.83863080684596\n",
      "Episode: 410\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 410 Training loss: 74.5787 Explore P: 0.1714\n",
      "37.95609756097561\n",
      "Episode: 411\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 411 Training loss: 78.7959 Explore P: 0.1713\n",
      "38.08759124087591\n",
      "Episode: 412\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 412 Training loss: 70.0056 Explore P: 0.1713\n",
      "38.220873786407765\n",
      "Episode: 413\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 413 Training loss: 94.8253 Explore P: 0.1712\n",
      "38.355932203389834\n",
      "Episode: 414\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 414 Training loss: 91.8142 Explore P: 0.1712\n",
      "38.48550724637681\n",
      "Episode: 415\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 415 Training loss: 87.7863 Explore P: 0.1711\n",
      "38.612048192771084\n",
      "Episode: 416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 7 timesteps\n",
      "Episode: 416 Training loss: 88.4538 Explore P: 0.1710\n",
      "38.74278846153846\n",
      "Episode: 417\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 417 Training loss: 76.4645 Explore P: 0.1710\n",
      "38.87290167865707\n",
      "Episode: 418\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 418 Training loss: 74.0577 Explore P: 0.1709\n",
      "38.98803827751196\n",
      "Episode: 419\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 419 Training loss: 60.2042 Explore P: 0.1708\n",
      "39.114558472553696\n",
      "Episode: 420\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 420 Training loss: 74.2024 Explore P: 0.1708\n",
      "39.25\n",
      "Episode: 421\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 421 Training loss: 89.2059 Explore P: 0.1707\n",
      "39.365795724465556\n",
      "Episode: 422\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 422 Training loss: 83.7504 Explore P: 0.1706\n",
      "39.485781990521325\n",
      "Episode: 423\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 423 Training loss: 88.7092 Explore P: 0.1706\n",
      "39.621749408983455\n",
      "Episode: 424\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 424 Training loss: 70.9235 Explore P: 0.1705\n",
      "39.74764150943396\n",
      "Episode: 425\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 425 Training loss: 71.6922 Explore P: 0.1705\n",
      "39.87529411764706\n",
      "Episode: 426\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 426 Training loss: 70.1956 Explore P: 0.1704\n",
      "40.0\n",
      "Episode: 427\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 427 Training loss: 81.7086 Explore P: 0.1703\n",
      "40.121779859484775\n",
      "Episode: 428\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 428 Training loss: 74.2879 Explore P: 0.1703\n",
      "40.23831775700935\n",
      "Episode: 429\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 429 Training loss: 80.1891 Explore P: 0.1702\n",
      "40.36130536130536\n",
      "Episode: 430\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 430 Training loss: 64.8109 Explore P: 0.1701\n",
      "40.46976744186046\n",
      "Episode: 431\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 431 Training loss: 74.0752 Explore P: 0.1700\n",
      "40.58932714617169\n",
      "Episode: 432\n",
      "Reached the goal after 37 timesteps\n",
      "Episode: 432 Training loss: 64.5518 Explore P: 0.1698\n",
      "40.6412037037037\n",
      "Episode: 433\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 433 Training loss: 86.7688 Explore P: 0.1697\n",
      "40.75981524249423\n",
      "Episode: 434\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 434 Training loss: 82.4098 Explore P: 0.1697\n",
      "40.87557603686636\n",
      "Episode: 435\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 435 Training loss: 82.0111 Explore P: 0.1696\n",
      "41.0\n",
      "Episode: 436\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 436 Training loss: 79.2421 Explore P: 0.1695\n",
      "41.10091743119266\n",
      "Episode: 437\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 437 Training loss: 93.9897 Explore P: 0.1695\n",
      "41.224256292906176\n",
      "Episode: 438\n",
      "Reached the goal after 25 timesteps\n",
      "Episode: 438 Training loss: 83.5969 Explore P: 0.1693\n",
      "41.3013698630137\n",
      "Episode: 439\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 439 Training loss: 92.3809 Explore P: 0.1692\n",
      "41.41913439635535\n",
      "Episode: 440\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 440 Training loss: 68.6995 Explore P: 0.1692\n",
      "41.54090909090909\n",
      "Episode: 441\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 441 Training loss: 80.5196 Explore P: 0.1691\n",
      "41.641723356009074\n",
      "Episode: 442\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 442 Training loss: 81.4013 Explore P: 0.1690\n",
      "41.7579185520362\n",
      "Episode: 443\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 443 Training loss: 87.7822 Explore P: 0.1689\n",
      "41.862302483069975\n",
      "Episode: 444\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 444 Training loss: 78.0221 Explore P: 0.1688\n",
      "41.968468468468465\n",
      "Episode: 445\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 445 Training loss: 79.4733 Explore P: 0.1688\n",
      "42.08539325842697\n",
      "Episode: 446\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 446 Training loss: 79.7902 Explore P: 0.1687\n",
      "42.199551569506724\n",
      "Episode: 447\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 447 Training loss: 94.2471 Explore P: 0.1687\n",
      "42.308724832214764\n",
      "Episode: 448\n",
      "Reached the goal after 37 timesteps\n",
      "Episode: 448 Training loss: 81.6007 Explore P: 0.1684\n",
      "42.354910714285715\n",
      "Episode: 449\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 449 Training loss: 79.8194 Explore P: 0.1684\n",
      "42.47216035634744\n",
      "Episode: 450\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 450 Training loss: 85.9171 Explore P: 0.1683\n",
      "42.58222222222222\n",
      "Episode: 451\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 451 Training loss: 97.3332 Explore P: 0.1683\n",
      "42.69623059866962\n",
      "Episode: 452\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 452 Training loss: 88.9307 Explore P: 0.1682\n",
      "42.807522123893804\n",
      "Episode: 453\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 453 Training loss: 78.8868 Explore P: 0.1682\n",
      "42.91832229580574\n",
      "Episode: 454\n",
      "Reached the goal after 32 timesteps\n",
      "Episode: 454 Training loss: 72.2963 Explore P: 0.1679\n",
      "42.97356828193833\n",
      "Episode: 455\n",
      "Reached the goal after 51 timesteps\n",
      "Episode: 455 Training loss: 65.4284 Explore P: 0.1676\n",
      "42.98681318681319\n",
      "Episode: 456\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 456 Training loss: 78.9832 Explore P: 0.1675\n",
      "43.098684210526315\n",
      "Episode: 457\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 457 Training loss: 89.5630 Explore P: 0.1675\n",
      "43.21006564551422\n",
      "Episode: 458\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 458 Training loss: 78.4251 Explore P: 0.1675\n",
      "43.327510917030565\n",
      "Episode: 459\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 459 Training loss: 89.0670 Explore P: 0.1674\n",
      "43.431372549019606\n",
      "Episode: 460\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 460 Training loss: 86.4178 Explore P: 0.1673\n",
      "43.52173913043478\n",
      "Episode: 461\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 461 Training loss: 73.3459 Explore P: 0.1672\n",
      "43.61605206073753\n",
      "Episode: 462\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 462 Training loss: 88.1484 Explore P: 0.1670\n",
      "43.6948051948052\n",
      "Episode: 463\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 463 Training loss: 93.9671 Explore P: 0.1670\n",
      "43.79913606911447\n",
      "Episode: 464\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 464 Training loss: 89.1851 Explore P: 0.1669\n",
      "43.883620689655174\n",
      "Episode: 465\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 465 Training loss: 73.2322 Explore P: 0.1668\n",
      "43.98494623655914\n",
      "Episode: 466\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 466 Training loss: 84.0483 Explore P: 0.1667\n",
      "44.08583690987125\n",
      "Episode: 467\n",
      "Reached the goal after 88 timesteps\n",
      "Episode: 467 Training loss: 86.9374 Explore P: 0.1661\n",
      "44.01713062098501\n",
      "Episode: 468\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 468 Training loss: 84.2743 Explore P: 0.1661\n",
      "44.113247863247864\n",
      "Episode: 469\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 469 Training loss: 104.7806 Explore P: 0.1660\n",
      "44.22174840085288\n",
      "Episode: 470\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 470 Training loss: 66.6625 Explore P: 0.1660\n",
      "44.329787234042556\n",
      "Episode: 471\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 471 Training loss: 81.2665 Explore P: 0.1659\n",
      "44.42887473460722\n",
      "Episode: 472\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 472 Training loss: 82.4237 Explore P: 0.1659\n",
      "44.529661016949156\n",
      "Episode: 473\n",
      "Reached the goal after 99 timesteps\n",
      "Episode: 473 Training loss: 86.8771 Explore P: 0.1652\n",
      "44.43763213530655\n",
      "Episode: 474\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 474 Training loss: 96.5804 Explore P: 0.1652\n",
      "44.54641350210971\n",
      "Episode: 475\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 475 Training loss: 92.2435 Explore P: 0.1651\n",
      "44.64631578947368\n",
      "Episode: 476\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 476 Training loss: 91.2300 Explore P: 0.1650\n",
      "44.74159663865546\n",
      "Episode: 477\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 477 Training loss: 86.5108 Explore P: 0.1650\n",
      "44.85115303983228\n",
      "Episode: 478\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 478 Training loss: 85.3776 Explore P: 0.1649\n",
      "44.92468619246862\n",
      "Episode: 479\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 479 Training loss: 94.0805 Explore P: 0.1648\n",
      "45.01670146137787\n",
      "Episode: 480\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 480 Training loss: 87.5736 Explore P: 0.1647\n",
      "45.104166666666664\n",
      "Episode: 481\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 481 Training loss: 100.6963 Explore P: 0.1646\n",
      "45.19126819126819\n",
      "Episode: 482\n",
      "Reached the goal after 55 timesteps\n",
      "Episode: 482 Training loss: 76.9388 Explore P: 0.1643\n",
      "45.190871369294605\n",
      "Episode: 483\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 483 Training loss: 70.9705 Explore P: 0.1642\n",
      "45.28364389233955\n",
      "Episode: 484\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 484 Training loss: 87.9069 Explore P: 0.1641\n",
      "45.38636363636363\n",
      "Episode: 485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 9 timesteps\n",
      "Episode: 485 Training loss: 97.0190 Explore P: 0.1641\n",
      "45.48041237113402\n",
      "Episode: 486\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 486 Training loss: 85.9185 Explore P: 0.1640\n",
      "45.56995884773662\n",
      "Episode: 487\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 487 Training loss: 85.2374 Explore P: 0.1640\n",
      "45.667351129363446\n",
      "Episode: 488\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 488 Training loss: 98.4555 Explore P: 0.1639\n",
      "45.76434426229508\n",
      "Episode: 489\n",
      "Reached the goal after 82 timesteps\n",
      "Episode: 489 Training loss: 99.0726 Explore P: 0.1634\n",
      "45.70756646216769\n",
      "Episode: 490\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 490 Training loss: 85.0044 Explore P: 0.1633\n",
      "45.80204081632653\n",
      "Episode: 491\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 491 Training loss: 90.2291 Explore P: 0.1633\n",
      "45.89816700610998\n",
      "Episode: 492\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 492 Training loss: 77.2221 Explore P: 0.1632\n",
      "45.989837398373986\n",
      "Episode: 493\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 493 Training loss: 85.8735 Explore P: 0.1632\n",
      "46.089249492900606\n",
      "Episode: 494\n",
      "Reached the goal after 72 timesteps\n",
      "Episode: 494 Training loss: 87.8951 Explore P: 0.1627\n",
      "46.05263157894737\n",
      "Episode: 495\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 495 Training loss: 86.2329 Explore P: 0.1627\n",
      "46.14545454545455\n",
      "Episode: 496\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 496 Training loss: 81.2304 Explore P: 0.1626\n",
      "46.243951612903224\n",
      "Episode: 497\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 497 Training loss: 84.9362 Explore P: 0.1626\n",
      "46.34004024144869\n",
      "Episode: 498\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 498 Training loss: 96.1110 Explore P: 0.1625\n",
      "46.4277108433735\n",
      "Episode: 499\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 499 Training loss: 92.2897 Explore P: 0.1625\n",
      "46.521042084168336\n",
      "Episode: 500\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 500 Training loss: 85.4746 Explore P: 0.1624\n",
      "46.61\n",
      "Episode: 501\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 501 Training loss: 93.8069 Explore P: 0.1624\n",
      "46.706586826347305\n",
      "Episode: 502\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 502 Training loss: 94.8720 Explore P: 0.1623\n",
      "46.79482071713147\n",
      "Episode: 503\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 503 Training loss: 108.2015 Explore P: 0.1622\n",
      "46.86878727634195\n",
      "Episode: 504\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 504 Training loss: 88.3074 Explore P: 0.1621\n",
      "46.942460317460316\n",
      "Episode: 505\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 505 Training loss: 94.2851 Explore P: 0.1620\n",
      "47.02970297029703\n",
      "Episode: 506\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 506 Training loss: 76.6885 Explore P: 0.1620\n",
      "47.11857707509881\n",
      "Episode: 507\n",
      "Reached the goal after 50 timesteps\n",
      "Episode: 507 Training loss: 96.0738 Explore P: 0.1616\n",
      "47.124260355029584\n",
      "Episode: 508\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 508 Training loss: 104.1639 Explore P: 0.1616\n",
      "47.218503937007874\n",
      "Episode: 509\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 509 Training loss: 94.1840 Explore P: 0.1615\n",
      "47.30255402750491\n",
      "Episode: 510\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 510 Training loss: 105.4006 Explore P: 0.1615\n",
      "47.38039215686275\n",
      "Episode: 511\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 511 Training loss: 98.8947 Explore P: 0.1614\n",
      "47.471624266144815\n",
      "Episode: 512\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 512 Training loss: 86.6835 Explore P: 0.1614\n",
      "47.5625\n",
      "Episode: 513\n",
      "Reached the goal after 22 timesteps\n",
      "Episode: 513 Training loss: 94.1237 Explore P: 0.1612\n",
      "47.62183235867447\n",
      "Episode: 514\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 514 Training loss: 84.1219 Explore P: 0.1612\n",
      "47.71400778210117\n",
      "Episode: 515\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 515 Training loss: 91.4590 Explore P: 0.1611\n",
      "47.803883495145634\n",
      "Episode: 516\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 516 Training loss: 92.9663 Explore P: 0.1611\n",
      "47.88178294573643\n",
      "Episode: 517\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 517 Training loss: 87.9514 Explore P: 0.1610\n",
      "47.970986460348165\n",
      "Episode: 518\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 518 Training loss: 89.8503 Explore P: 0.1610\n",
      "48.05598455598456\n",
      "Episode: 519\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 519 Training loss: 90.3368 Explore P: 0.1609\n",
      "48.14258188824663\n",
      "Episode: 520\n",
      "Reached the goal after 27 timesteps\n",
      "Episode: 520 Training loss: 88.5233 Explore P: 0.1608\n",
      "48.190384615384616\n",
      "Episode: 521\n",
      "Reached the goal after 22 timesteps\n",
      "Episode: 521 Training loss: 94.1094 Explore P: 0.1606\n",
      "48.24760076775432\n",
      "Episode: 522\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 522 Training loss: 100.5465 Explore P: 0.1606\n",
      "48.333333333333336\n",
      "Episode: 523\n",
      "Reached the goal after 58 timesteps\n",
      "Episode: 523 Training loss: 93.2885 Explore P: 0.1602\n",
      "48.32122370936902\n",
      "Episode: 524\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 524 Training loss: 71.6720 Explore P: 0.1602\n",
      "48.406488549618324\n",
      "Episode: 525\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 525 Training loss: 86.2047 Explore P: 0.1601\n",
      "48.48952380952381\n",
      "Episode: 526\n",
      "Reached the goal after 39 timesteps\n",
      "Episode: 526 Training loss: 98.3795 Explore P: 0.1599\n",
      "48.51330798479088\n",
      "Episode: 527\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 527 Training loss: 86.9386 Explore P: 0.1597\n",
      "48.573055028462996\n",
      "Episode: 528\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 528 Training loss: 85.5487 Explore P: 0.1597\n",
      "48.65340909090909\n",
      "Episode: 529\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 529 Training loss: 91.4029 Explore P: 0.1596\n",
      "48.731568998109644\n",
      "Episode: 530\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 530 Training loss: 89.3280 Explore P: 0.1596\n",
      "48.820754716981135\n",
      "Episode: 531\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 531 Training loss: 73.3193 Explore P: 0.1595\n",
      "48.90772128060264\n",
      "Episode: 532\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 532 Training loss: 93.7296 Explore P: 0.1595\n",
      "48.99624060150376\n",
      "Episode: 533\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 533 Training loss: 99.5901 Explore P: 0.1595\n",
      "49.08255159474672\n",
      "Episode: 534\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 534 Training loss: 97.7565 Explore P: 0.1594\n",
      "49.159176029962545\n",
      "Episode: 535\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 535 Training loss: 80.0775 Explore P: 0.1594\n",
      "49.2392523364486\n",
      "Episode: 536\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 536 Training loss: 87.4821 Explore P: 0.1593\n",
      "49.31716417910448\n",
      "Episode: 537\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 537 Training loss: 88.0567 Explore P: 0.1591\n",
      "49.36312849162011\n",
      "Episode: 538\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 538 Training loss: 94.4797 Explore P: 0.1591\n",
      "49.44237918215613\n",
      "Episode: 539\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 539 Training loss: 101.7327 Explore P: 0.1591\n",
      "49.526901669758814\n",
      "Episode: 540\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 540 Training loss: 94.1761 Explore P: 0.1590\n",
      "49.6\n",
      "Episode: 541\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 541 Training loss: 87.5210 Explore P: 0.1589\n",
      "49.676524953789276\n",
      "Episode: 542\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 542 Training loss: 74.9914 Explore P: 0.1589\n",
      "49.75830258302583\n",
      "Episode: 543\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 543 Training loss: 88.9628 Explore P: 0.1588\n",
      "49.83609576427256\n",
      "Episode: 544\n",
      "Reached the goal after 22 timesteps\n",
      "Episode: 544 Training loss: 101.2780 Explore P: 0.1587\n",
      "49.887867647058826\n",
      "Episode: 545\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 545 Training loss: 110.3845 Explore P: 0.1587\n",
      "49.97064220183486\n",
      "Episode: 546\n",
      "Reached the goal after 33 timesteps\n",
      "Episode: 546 Training loss: 96.7288 Explore P: 0.1585\n",
      "50.001831501831504\n",
      "Episode: 547\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 547 Training loss: 96.6615 Explore P: 0.1584\n",
      "50.074954296160875\n",
      "Episode: 548\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 548 Training loss: 101.7587 Explore P: 0.1583\n",
      "50.1478102189781\n",
      "Episode: 549\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 549 Training loss: 98.3827 Explore P: 0.1583\n",
      "50.22768670309654\n",
      "Episode: 550\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 550 Training loss: 104.0212 Explore P: 0.1583\n",
      "50.31090909090909\n",
      "Episode: 551\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 551 Training loss: 82.8353 Explore P: 0.1582\n",
      "50.37205081669691\n",
      "Episode: 552\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 552 Training loss: 92.9242 Explore P: 0.1581\n",
      "50.447463768115945\n",
      "Episode: 553\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 553 Training loss: 90.7566 Explore P: 0.1581\n",
      "50.520795660036164\n",
      "Episode: 554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 3 timesteps\n",
      "Episode: 554 Training loss: 92.1382 Explore P: 0.1580\n",
      "50.604693140794225\n",
      "Episode: 555\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 555 Training loss: 104.1448 Explore P: 0.1580\n",
      "50.68648648648649\n",
      "Episode: 556\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 556 Training loss: 80.3405 Explore P: 0.1580\n",
      "50.76798561151079\n",
      "Episode: 557\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 557 Training loss: 102.6777 Explore P: 0.1579\n",
      "50.83842010771993\n",
      "Episode: 558\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 558 Training loss: 88.5639 Explore P: 0.1578\n",
      "50.89068100358423\n",
      "Episode: 559\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 559 Training loss: 92.2594 Explore P: 0.1577\n",
      "50.96243291592129\n",
      "Episode: 560\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 560 Training loss: 93.3431 Explore P: 0.1577\n",
      "51.042857142857144\n",
      "Episode: 561\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 561 Training loss: 93.6001 Explore P: 0.1576\n",
      "51.11229946524064\n",
      "Episode: 562\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 562 Training loss: 78.1954 Explore P: 0.1576\n",
      "51.1779359430605\n",
      "Episode: 563\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 563 Training loss: 99.4918 Explore P: 0.1575\n",
      "51.241563055062166\n",
      "Episode: 564\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 564 Training loss: 105.1380 Explore P: 0.1574\n",
      "51.3031914893617\n",
      "Episode: 565\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 565 Training loss: 100.9799 Explore P: 0.1574\n",
      "51.38053097345133\n",
      "Episode: 566\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 566 Training loss: 108.7930 Explore P: 0.1573\n",
      "51.459363957597176\n",
      "Episode: 567\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 567 Training loss: 104.0617 Explore P: 0.1573\n",
      "51.5379188712522\n",
      "Episode: 568\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 568 Training loss: 106.4065 Explore P: 0.1573\n",
      "51.609154929577464\n",
      "Episode: 569\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 569 Training loss: 101.5425 Explore P: 0.1572\n",
      "51.68014059753954\n",
      "Episode: 570\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 570 Training loss: 93.2251 Explore P: 0.1571\n",
      "51.73508771929824\n",
      "Episode: 571\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 571 Training loss: 105.2008 Explore P: 0.1570\n",
      "51.80035026269702\n",
      "Episode: 572\n",
      "Reached the goal after 29 timesteps\n",
      "Episode: 572 Training loss: 98.7587 Explore P: 0.1569\n",
      "51.83391608391609\n",
      "Episode: 573\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 573 Training loss: 103.1669 Explore P: 0.1568\n",
      "51.8935427574171\n",
      "Episode: 574\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 574 Training loss: 94.9263 Explore P: 0.1567\n",
      "51.951219512195124\n",
      "Episode: 575\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 575 Training loss: 95.7434 Explore P: 0.1566\n",
      "52.02086956521739\n",
      "Episode: 576\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 576 Training loss: 133.6159 Explore P: 0.1566\n",
      "52.092013888888886\n",
      "Episode: 577\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 577 Training loss: 123.5413 Explore P: 0.1565\n",
      "52.1629116117851\n",
      "Episode: 578\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 578 Training loss: 102.9260 Explore P: 0.1565\n",
      "52.23702422145329\n",
      "Episode: 579\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 579 Training loss: 92.3173 Explore P: 0.1565\n",
      "52.30569948186528\n",
      "Episode: 580\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 580 Training loss: 95.7447 Explore P: 0.1564\n",
      "52.37931034482759\n",
      "Episode: 581\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 581 Training loss: 95.1580 Explore P: 0.1564\n",
      "52.45094664371773\n",
      "Episode: 582\n",
      "Reached the goal after 18 timesteps\n",
      "Episode: 582 Training loss: 99.9863 Explore P: 0.1563\n",
      "52.50171821305842\n",
      "Episode: 583\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 583 Training loss: 94.2672 Explore P: 0.1562\n",
      "52.57118353344769\n",
      "Episode: 584\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 584 Training loss: 95.3930 Explore P: 0.1562\n",
      "52.638698630136986\n",
      "Episode: 585\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 585 Training loss: 104.8917 Explore P: 0.1561\n",
      "52.68547008547009\n",
      "Episode: 586\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 586 Training loss: 92.8638 Explore P: 0.1560\n",
      "52.75938566552901\n",
      "Episode: 587\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 587 Training loss: 107.1140 Explore P: 0.1560\n",
      "52.82793867120954\n",
      "Episode: 588\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 588 Training loss: 96.9021 Explore P: 0.1559\n",
      "52.892857142857146\n",
      "Episode: 589\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 589 Training loss: 101.7238 Explore P: 0.1559\n",
      "52.95925297113752\n",
      "Episode: 590\n",
      "Reached the goal after 147 timesteps\n",
      "Episode: 590 Training loss: 125.0470 Explore P: 0.1551\n",
      "52.78983050847457\n",
      "Episode: 591\n",
      "Reached the goal after 24 timesteps\n",
      "Episode: 591 Training loss: 108.1358 Explore P: 0.1549\n",
      "52.82910321489002\n",
      "Episode: 592\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 592 Training loss: 109.1596 Explore P: 0.1549\n",
      "52.888513513513516\n",
      "Episode: 593\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 593 Training loss: 110.5393 Explore P: 0.1548\n",
      "52.951096121416526\n",
      "Episode: 594\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 594 Training loss: 105.2881 Explore P: 0.1547\n",
      "53.01683501683502\n",
      "Episode: 595\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 595 Training loss: 104.4993 Explore P: 0.1547\n",
      "53.08739495798319\n",
      "Episode: 596\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 596 Training loss: 96.2016 Explore P: 0.1547\n",
      "53.15771812080537\n",
      "Episode: 597\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 597 Training loss: 93.3897 Explore P: 0.1546\n",
      "53.222780569514235\n",
      "Episode: 598\n",
      "Reached the goal after 127 timesteps\n",
      "Episode: 598 Training loss: 115.6398 Explore P: 0.1539\n",
      "53.08862876254181\n",
      "Episode: 599\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 599 Training loss: 100.2923 Explore P: 0.1539\n",
      "53.15692821368948\n",
      "Episode: 600\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 600 Training loss: 107.9326 Explore P: 0.1538\n",
      "53.221666666666664\n",
      "Episode: 601\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 601 Training loss: 103.0082 Explore P: 0.1538\n",
      "53.28452579034942\n",
      "Episode: 602\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 602 Training loss: 107.4771 Explore P: 0.1538\n",
      "53.352159468438536\n",
      "Episode: 603\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 603 Training loss: 80.1010 Explore P: 0.1537\n",
      "53.40961857379768\n",
      "Episode: 604\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 604 Training loss: 102.0461 Explore P: 0.1536\n",
      "53.466887417218544\n",
      "Episode: 605\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 605 Training loss: 97.0402 Explore P: 0.1536\n",
      "53.53553719008264\n",
      "Episode: 606\n",
      "Reached the goal after 19 timesteps\n",
      "Episode: 606 Training loss: 119.0045 Explore P: 0.1535\n",
      "53.58085808580858\n",
      "Episode: 607\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 607 Training loss: 108.8183 Explore P: 0.1534\n",
      "53.63591433278418\n",
      "Episode: 608\n",
      "Reached the goal after 30 timesteps\n",
      "Episode: 608 Training loss: 108.0181 Explore P: 0.1532\n",
      "53.66282894736842\n",
      "Episode: 609\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 609 Training loss: 109.5944 Explore P: 0.1532\n",
      "53.72906403940887\n",
      "Episode: 610\n",
      "Reached the goal after 37 timesteps\n",
      "Episode: 610 Training loss: 105.5622 Explore P: 0.1530\n",
      "53.74426229508197\n",
      "Episode: 611\n",
      "Reached the goal after 77 timesteps\n",
      "Episode: 611 Training loss: 96.7728 Explore P: 0.1526\n",
      "53.69394435351882\n",
      "Episode: 612\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 612 Training loss: 81.2868 Explore P: 0.1525\n",
      "53.75653594771242\n",
      "Episode: 613\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 613 Training loss: 117.4171 Explore P: 0.1525\n",
      "53.8189233278956\n",
      "Episode: 614\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 614 Training loss: 111.5358 Explore P: 0.1524\n",
      "53.881107491856675\n",
      "Episode: 615\n",
      "Reached the goal after 18 timesteps\n",
      "Episode: 615 Training loss: 118.1479 Explore P: 0.1523\n",
      "53.926829268292686\n",
      "Episode: 616\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 616 Training loss: 114.6943 Explore P: 0.1523\n",
      "53.99512987012987\n",
      "Episode: 617\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 617 Training loss: 104.6188 Explore P: 0.1523\n",
      "54.05996758508914\n",
      "Episode: 618\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 618 Training loss: 95.2597 Explore P: 0.1523\n",
      "54.12621359223301\n",
      "Episode: 619\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 619 Training loss: 111.8414 Explore P: 0.1522\n",
      "54.19386106623586\n",
      "Episode: 620\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 620 Training loss: 93.3204 Explore P: 0.1522\n",
      "54.24677419354839\n",
      "Episode: 621\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 621 Training loss: 109.7070 Explore P: 0.1521\n",
      "54.309178743961354\n",
      "Episode: 622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 4 timesteps\n",
      "Episode: 622 Training loss: 95.7440 Explore P: 0.1521\n",
      "54.37620578778135\n",
      "Episode: 623\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 623 Training loss: 99.4311 Explore P: 0.1520\n",
      "54.42536115569823\n",
      "Episode: 624\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 624 Training loss: 111.3986 Explore P: 0.1520\n",
      "54.49038461538461\n",
      "Episode: 625\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 625 Training loss: 126.2370 Explore P: 0.1519\n",
      "54.5568\n",
      "Episode: 626\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 626 Training loss: 110.6643 Explore P: 0.1519\n",
      "54.61821086261981\n",
      "Episode: 627\n",
      "Reached the goal after 119 timesteps\n",
      "Episode: 627 Training loss: 95.7396 Explore P: 0.1513\n",
      "54.50079744816587\n",
      "Episode: 628\n",
      "Reached the goal after 49 timesteps\n",
      "Episode: 628 Training loss: 121.2543 Explore P: 0.1510\n",
      "54.495222929936304\n",
      "Episode: 629\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 629 Training loss: 116.4345 Explore P: 0.1510\n",
      "54.55802861685215\n",
      "Episode: 630\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 630 Training loss: 126.0507 Explore P: 0.1509\n",
      "54.61746031746032\n",
      "Episode: 631\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 631 Training loss: 97.9751 Explore P: 0.1509\n",
      "54.67828843106181\n",
      "Episode: 632\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 632 Training loss: 109.8592 Explore P: 0.1509\n",
      "54.735759493670884\n",
      "Episode: 633\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 633 Training loss: 112.5754 Explore P: 0.1508\n",
      "54.791469194312796\n",
      "Episode: 634\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 634 Training loss: 116.0978 Explore P: 0.1508\n",
      "54.85488958990536\n",
      "Episode: 635\n",
      "Reached the goal after 25 timesteps\n",
      "Episode: 635 Training loss: 105.4204 Explore P: 0.1506\n",
      "54.886614173228345\n",
      "Episode: 636\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 636 Training loss: 98.1949 Explore P: 0.1506\n",
      "54.941823899371066\n",
      "Episode: 637\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 637 Training loss: 95.3637 Explore P: 0.1505\n",
      "54.99372056514914\n",
      "Episode: 638\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 638 Training loss: 108.9583 Explore P: 0.1505\n",
      "55.05485893416928\n",
      "Episode: 639\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 639 Training loss: 120.5815 Explore P: 0.1504\n",
      "55.11267605633803\n",
      "Episode: 640\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 640 Training loss: 97.1886 Explore P: 0.1504\n",
      "55.159375\n",
      "Episode: 641\n",
      "Reached the goal after 213 timesteps\n",
      "Episode: 641 Training loss: 115.5953 Explore P: 0.1493\n",
      "54.89703588143526\n",
      "Episode: 642\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 642 Training loss: 127.7072 Explore P: 0.1492\n",
      "54.95638629283489\n",
      "Episode: 643\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 643 Training loss: 97.2098 Explore P: 0.1492\n",
      "55.01244167962675\n",
      "Episode: 644\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 644 Training loss: 115.3934 Explore P: 0.1492\n",
      "55.06832298136646\n",
      "Episode: 645\n",
      "Reached the goal after 34 timesteps\n",
      "Episode: 645 Training loss: 108.1458 Explore P: 0.1490\n",
      "55.08527131782946\n",
      "Episode: 646\n",
      "Reached the goal after 38 timesteps\n",
      "Episode: 646 Training loss: 113.8999 Explore P: 0.1488\n",
      "55.09597523219814\n",
      "Episode: 647\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 647 Training loss: 103.0535 Explore P: 0.1488\n",
      "55.15765069551777\n",
      "Episode: 648\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 648 Training loss: 100.2984 Explore P: 0.1487\n",
      "55.21141975308642\n",
      "Episode: 649\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 649 Training loss: 100.3522 Explore P: 0.1486\n",
      "55.25731895223421\n",
      "Episode: 650\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 650 Training loss: 117.1251 Explore P: 0.1486\n",
      "55.32\n",
      "Episode: 651\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 651 Training loss: 99.6707 Explore P: 0.1486\n",
      "55.37327188940092\n",
      "Episode: 652\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 652 Training loss: 121.1717 Explore P: 0.1485\n",
      "55.421779141104295\n",
      "Episode: 653\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 653 Training loss: 92.6641 Explore P: 0.1484\n",
      "55.47166921898928\n",
      "Episode: 654\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 654 Training loss: 108.3724 Explore P: 0.1484\n",
      "55.52905198776758\n",
      "Episode: 655\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 655 Training loss: 111.0906 Explore P: 0.1483\n",
      "55.58320610687023\n",
      "Episode: 656\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 656 Training loss: 106.5189 Explore P: 0.1483\n",
      "55.63719512195122\n",
      "Episode: 657\n",
      "Reached the goal after 47 timesteps\n",
      "Episode: 657 Training loss: 115.4399 Explore P: 0.1481\n",
      "55.63318112633181\n",
      "Episode: 658\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 658 Training loss: 112.4742 Explore P: 0.1480\n",
      "55.682370820668694\n",
      "Episode: 659\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 659 Training loss: 116.8695 Explore P: 0.1480\n",
      "55.73899848254932\n",
      "Episode: 660\n",
      "Reached the goal after 27 timesteps\n",
      "Episode: 660 Training loss: 109.5151 Explore P: 0.1478\n",
      "55.765151515151516\n",
      "Episode: 661\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 661 Training loss: 103.3993 Explore P: 0.1478\n",
      "55.82753403933434\n",
      "Episode: 662\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 662 Training loss: 101.7313 Explore P: 0.1478\n",
      "55.88519637462235\n",
      "Episode: 663\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 663 Training loss: 123.4361 Explore P: 0.1477\n",
      "55.93815987933635\n",
      "Episode: 664\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 664 Training loss: 115.0484 Explore P: 0.1477\n",
      "55.993975903614455\n",
      "Episode: 665\n",
      "Reached the goal after 72 timesteps\n",
      "Episode: 665 Training loss: 130.3197 Explore P: 0.1473\n",
      "55.95187969924812\n",
      "Episode: 666\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 666 Training loss: 104.0692 Explore P: 0.1473\n",
      "56.010510510510514\n",
      "Episode: 667\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 667 Training loss: 94.2476 Explore P: 0.1473\n",
      "56.06896551724138\n",
      "Episode: 668\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 668 Training loss: 101.4566 Explore P: 0.1472\n",
      "56.12125748502994\n",
      "Episode: 669\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 669 Training loss: 123.0819 Explore P: 0.1472\n",
      "56.176382660687594\n",
      "Episode: 670\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 670 Training loss: 118.9004 Explore P: 0.1472\n",
      "56.234328358208955\n",
      "Episode: 671\n",
      "Reached the goal after 27 timesteps\n",
      "Episode: 671 Training loss: 106.5898 Explore P: 0.1470\n",
      "56.25931445603577\n",
      "Episode: 672\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 672 Training loss: 116.4700 Explore P: 0.1470\n",
      "56.308035714285715\n",
      "Episode: 673\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 673 Training loss: 120.0453 Explore P: 0.1469\n",
      "56.35661218424963\n",
      "Episode: 674\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 674 Training loss: 111.3358 Explore P: 0.1469\n",
      "56.409495548961424\n",
      "Episode: 675\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 675 Training loss: 96.6383 Explore P: 0.1468\n",
      "56.465185185185184\n",
      "Episode: 676\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 676 Training loss: 103.2399 Explore P: 0.1468\n",
      "56.5207100591716\n",
      "Episode: 677\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 677 Training loss: 110.9077 Explore P: 0.1468\n",
      "56.57311669128508\n",
      "Episode: 678\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 678 Training loss: 113.6774 Explore P: 0.1467\n",
      "56.6283185840708\n",
      "Episode: 679\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 679 Training loss: 125.8187 Explore P: 0.1467\n",
      "56.67893961708395\n",
      "Episode: 680\n",
      "Reached the goal after 40 timesteps\n",
      "Episode: 680 Training loss: 114.8218 Explore P: 0.1465\n",
      "56.68382352941177\n",
      "Episode: 681\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 681 Training loss: 103.6635 Explore P: 0.1465\n",
      "56.73568281938326\n",
      "Episode: 682\n",
      "Reached the goal after 43 timesteps\n",
      "Episode: 682 Training loss: 109.6216 Explore P: 0.1463\n",
      "56.73607038123167\n",
      "Episode: 683\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 683 Training loss: 94.8179 Explore P: 0.1462\n",
      "56.789165446559295\n",
      "Episode: 684\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 684 Training loss: 112.1628 Explore P: 0.1462\n",
      "56.84649122807018\n",
      "Episode: 685\n",
      "Reached the goal after 47 timesteps\n",
      "Episode: 685 Training loss: 102.7485 Explore P: 0.1460\n",
      "56.84087591240876\n",
      "Episode: 686\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 686 Training loss: 114.6271 Explore P: 0.1459\n",
      "56.88921282798834\n",
      "Episode: 687\n",
      "Reached the goal after 193 timesteps\n",
      "Episode: 687 Training loss: 93.2626 Explore P: 0.1450\n",
      "56.67103347889374\n",
      "Episode: 688\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 688 Training loss: 95.3464 Explore P: 0.1450\n",
      "56.72529069767442\n",
      "Episode: 689\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 689 Training loss: 105.9984 Explore P: 0.1450\n",
      "56.776487663280115\n",
      "Episode: 690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 36 timesteps\n",
      "Episode: 690 Training loss: 101.0555 Explore P: 0.1448\n",
      "56.78695652173913\n",
      "Episode: 691\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 691 Training loss: 96.6492 Explore P: 0.1448\n",
      "56.84370477568741\n",
      "Episode: 692\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 692 Training loss: 84.9909 Explore P: 0.1447\n",
      "56.895953757225435\n",
      "Episode: 693\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 693 Training loss: 98.4096 Explore P: 0.1447\n",
      "56.94805194805195\n",
      "Episode: 694\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 694 Training loss: 102.1550 Explore P: 0.1447\n",
      "57.0\n",
      "Episode: 695\n",
      "Reached the goal after 131 timesteps\n",
      "Episode: 695 Training loss: 94.4374 Explore P: 0.1441\n",
      "56.87338129496403\n",
      "Episode: 696\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 696 Training loss: 104.8891 Explore P: 0.1440\n",
      "56.923850574712645\n",
      "Episode: 697\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 697 Training loss: 96.8140 Explore P: 0.1440\n",
      "56.972740315638454\n",
      "Episode: 698\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 698 Training loss: 107.9311 Explore P: 0.1439\n",
      "57.01719197707737\n",
      "Episode: 699\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 699 Training loss: 106.6759 Explore P: 0.1439\n",
      "57.06437768240343\n",
      "Episode: 700\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 700 Training loss: 108.3149 Explore P: 0.1439\n",
      "57.11857142857143\n",
      "Episode: 701\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 701 Training loss: 102.0863 Explore P: 0.1438\n",
      "57.172610556348076\n",
      "Episode: 702\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 702 Training loss: 104.5450 Explore P: 0.1438\n",
      "57.22792022792023\n",
      "Episode: 703\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 703 Training loss: 110.4897 Explore P: 0.1437\n",
      "57.26458036984353\n",
      "Episode: 704\n",
      "Reached the goal after 727 timesteps\n",
      "Episode: 704 Training loss: 115.2500 Explore P: 0.1407\n",
      "56.29261363636363\n",
      "Episode: 705\n",
      "Reached the goal after 23 timesteps\n",
      "Episode: 705 Training loss: 120.6577 Explore P: 0.1406\n",
      "56.32198581560284\n",
      "Episode: 706\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 706 Training loss: 107.5481 Explore P: 0.1405\n",
      "56.373937677053824\n",
      "Episode: 707\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 707 Training loss: 106.6024 Explore P: 0.1405\n",
      "56.42291371994342\n",
      "Episode: 708\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 708 Training loss: 78.2571 Explore P: 0.1405\n",
      "56.47316384180791\n",
      "Episode: 709\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 709 Training loss: 115.0074 Explore P: 0.1404\n",
      "56.52609308885754\n",
      "Episode: 710\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 710 Training loss: 113.5531 Explore P: 0.1404\n",
      "56.58028169014084\n",
      "Episode: 711\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 711 Training loss: 94.8438 Explore P: 0.1404\n",
      "56.635724331926866\n",
      "Episode: 712\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 712 Training loss: 115.3351 Explore P: 0.1403\n",
      "56.681179775280896\n",
      "Episode: 713\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 713 Training loss: 119.9978 Explore P: 0.1403\n",
      "56.73352033660589\n",
      "Episode: 714\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 714 Training loss: 106.0871 Explore P: 0.1403\n",
      "56.78851540616247\n",
      "Episode: 715\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 715 Training loss: 106.4930 Explore P: 0.1403\n",
      "56.84055944055944\n",
      "Episode: 716\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 716 Training loss: 101.2194 Explore P: 0.1402\n",
      "56.88268156424581\n",
      "Episode: 717\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 717 Training loss: 85.5094 Explore P: 0.1402\n",
      "56.93584379358438\n",
      "Episode: 718\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 718 Training loss: 102.4127 Explore P: 0.1401\n",
      "56.98467966573816\n",
      "Episode: 719\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 719 Training loss: 85.2934 Explore P: 0.1401\n",
      "57.03059805285118\n",
      "Episode: 720\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 720 Training loss: 102.6059 Explore P: 0.1401\n",
      "57.08611111111111\n",
      "Episode: 721\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 721 Training loss: 105.3212 Explore P: 0.1400\n",
      "57.133148404993065\n",
      "Episode: 722\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 722 Training loss: 106.8861 Explore P: 0.1400\n",
      "57.18005540166205\n",
      "Episode: 723\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 723 Training loss: 97.4649 Explore P: 0.1400\n",
      "57.23374827109267\n",
      "Episode: 724\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 724 Training loss: 98.1568 Explore P: 0.1400\n",
      "57.28867403314917\n",
      "Episode: 725\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 725 Training loss: 103.1260 Explore P: 0.1400\n",
      "57.34206896551724\n",
      "Episode: 726\n",
      "Reached the goal after 115 timesteps\n",
      "Episode: 726 Training loss: 100.7835 Explore P: 0.1395\n",
      "57.24242424242424\n",
      "Episode: 727\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 727 Training loss: 92.8940 Explore P: 0.1395\n",
      "57.29160935350757\n",
      "Episode: 728\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 728 Training loss: 115.4067 Explore P: 0.1394\n",
      "57.34065934065934\n",
      "Episode: 729\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 729 Training loss: 98.9140 Explore P: 0.1394\n",
      "57.39506172839506\n",
      "Episode: 730\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 730 Training loss: 101.4204 Explore P: 0.1394\n",
      "57.441095890410956\n",
      "Episode: 731\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 731 Training loss: 105.7845 Explore P: 0.1393\n",
      "57.49110807113543\n",
      "Episode: 732\n",
      "56.04644808743169\n",
      "Episode: 733\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 733 Training loss: 94.9728 Explore P: 0.1356\n",
      "56.096862210095495\n",
      "Episode: 734\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 734 Training loss: 93.0474 Explore P: 0.1355\n",
      "56.14850136239782\n",
      "Episode: 735\n",
      "Reached the goal after 360 timesteps\n",
      "Episode: 735 Training loss: 94.1507 Explore P: 0.1343\n",
      "55.71836734693878\n",
      "Episode: 736\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 736 Training loss: 94.3650 Explore P: 0.1343\n",
      "55.76902173913044\n",
      "Episode: 737\n",
      "Reached the goal after 33 timesteps\n",
      "Episode: 737 Training loss: 104.5151 Explore P: 0.1341\n",
      "55.7842605156038\n",
      "Episode: 738\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 738 Training loss: 102.2345 Explore P: 0.1341\n",
      "55.8089430894309\n",
      "Episode: 739\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 739 Training loss: 102.7810 Explore P: 0.1340\n",
      "55.859269282814616\n",
      "Episode: 740\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 740 Training loss: 96.3581 Explore P: 0.1340\n",
      "55.8972972972973\n",
      "Episode: 741\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 741 Training loss: 93.7153 Explore P: 0.1339\n",
      "55.94601889338731\n",
      "Episode: 742\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 742 Training loss: 111.0027 Explore P: 0.1339\n",
      "56.001347708894876\n",
      "Episode: 743\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 743 Training loss: 102.1695 Explore P: 0.1339\n",
      "56.047106325706594\n",
      "Episode: 744\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 744 Training loss: 93.0539 Explore P: 0.1339\n",
      "56.098118279569896\n",
      "Episode: 745\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 745 Training loss: 99.0680 Explore P: 0.1338\n",
      "56.151677852348996\n",
      "Episode: 746\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 746 Training loss: 105.6255 Explore P: 0.1338\n",
      "56.20375335120644\n",
      "Episode: 747\n",
      "Reached the goal after 2 timesteps\n",
      "Episode: 747 Training loss: 85.6806 Explore P: 0.1338\n",
      "56.25970548862115\n",
      "Episode: 748\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 748 Training loss: 104.0794 Explore P: 0.1338\n",
      "56.31149732620321\n",
      "Episode: 749\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 749 Training loss: 98.4014 Explore P: 0.1338\n",
      "56.360480640854476\n",
      "Episode: 750\n",
      "Reached the goal after 31 timesteps\n",
      "Episode: 750 Training loss: 102.6608 Explore P: 0.1337\n",
      "56.37733333333333\n",
      "Episode: 751\n",
      "Reached the goal after 54 timesteps\n",
      "Episode: 751 Training loss: 104.7959 Explore P: 0.1335\n",
      "56.363515312916114\n",
      "Episode: 752\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 752 Training loss: 99.9777 Explore P: 0.1334\n",
      "56.40824468085106\n",
      "Episode: 753\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 753 Training loss: 106.2415 Explore P: 0.1334\n",
      "56.46082337317397\n",
      "Episode: 754\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 754 Training loss: 99.6330 Explore P: 0.1334\n",
      "56.5106100795756\n",
      "Episode: 755\n",
      "Reached the goal after 805 timesteps\n",
      "Episode: 755 Training loss: 85.9605 Explore P: 0.1308\n",
      "55.501986754966886\n",
      "Episode: 756\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 756 Training loss: 96.3537 Explore P: 0.1308\n",
      "55.55555555555556\n",
      "Episode: 757\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 757 Training loss: 93.3489 Explore P: 0.1308\n",
      "55.603698811096436\n",
      "Episode: 758\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 758 Training loss: 90.4197 Explore P: 0.1308\n",
      "55.656992084432716\n",
      "Episode: 759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 5 timesteps\n",
      "Episode: 759 Training loss: 107.3459 Explore P: 0.1307\n",
      "55.70882740447958\n",
      "Episode: 760\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 760 Training loss: 112.5361 Explore P: 0.1307\n",
      "55.75657894736842\n",
      "Episode: 761\n",
      "Reached the goal after 55 timesteps\n",
      "Episode: 761 Training loss: 102.1176 Explore P: 0.1305\n",
      "55.74244415243101\n",
      "Episode: 762\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 762 Training loss: 80.3557 Explore P: 0.1305\n",
      "55.79265091863517\n",
      "Episode: 763\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 763 Training loss: 106.6132 Explore P: 0.1305\n",
      "55.84534731323722\n",
      "Episode: 764\n",
      "Reached the goal after 23 timesteps\n",
      "Episode: 764 Training loss: 93.0223 Explore P: 0.1304\n",
      "55.87303664921466\n",
      "Episode: 765\n",
      "Reached the goal after 116 timesteps\n",
      "Episode: 765 Training loss: 103.4446 Explore P: 0.1301\n",
      "55.77908496732026\n",
      "Episode: 766\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 766 Training loss: 99.1844 Explore P: 0.1300\n",
      "55.82767624020888\n",
      "Episode: 767\n",
      "Reached the goal after 24 timesteps\n",
      "Episode: 767 Training loss: 94.3386 Explore P: 0.1300\n",
      "55.853976531942635\n",
      "Episode: 768\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 768 Training loss: 96.5793 Explore P: 0.1299\n",
      "55.899739583333336\n",
      "Episode: 769\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 769 Training loss: 104.4434 Explore P: 0.1299\n",
      "55.94928478543563\n",
      "Episode: 770\n",
      "Reached the goal after 215 timesteps\n",
      "Episode: 770 Training loss: 114.1841 Explore P: 0.1293\n",
      "55.72727272727273\n",
      "Episode: 771\n",
      "Reached the goal after 136 timesteps\n",
      "Episode: 771 Training loss: 107.5555 Explore P: 0.1289\n",
      "55.608300907911804\n",
      "Episode: 772\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 772 Training loss: 104.4434 Explore P: 0.1289\n",
      "55.66062176165803\n",
      "Episode: 773\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 773 Training loss: 76.3271 Explore P: 0.1288\n",
      "55.70504527813713\n",
      "Episode: 774\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 774 Training loss: 94.4094 Explore P: 0.1288\n",
      "55.75581395348837\n",
      "Episode: 775\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 775 Training loss: 96.5502 Explore P: 0.1288\n",
      "55.806451612903224\n",
      "Episode: 776\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 776 Training loss: 100.8512 Explore P: 0.1288\n",
      "55.8569587628866\n",
      "Episode: 777\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 777 Training loss: 95.7088 Explore P: 0.1288\n",
      "55.907335907335906\n",
      "Episode: 778\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 778 Training loss: 87.6430 Explore P: 0.1287\n",
      "55.955012853470436\n",
      "Episode: 779\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 779 Training loss: 110.5111 Explore P: 0.1287\n",
      "55.98459563543004\n",
      "Episode: 780\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 780 Training loss: 99.2591 Explore P: 0.1287\n",
      "56.03076923076923\n",
      "Episode: 781\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 781 Training loss: 116.9133 Explore P: 0.1286\n",
      "56.07682458386684\n",
      "Episode: 782\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 782 Training loss: 99.0131 Explore P: 0.1286\n",
      "56.12276214833759\n",
      "Episode: 783\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 783 Training loss: 99.5112 Explore P: 0.1286\n",
      "56.17369093231162\n",
      "Episode: 784\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 784 Training loss: 91.7991 Explore P: 0.1286\n",
      "56.2219387755102\n",
      "Episode: 785\n",
      "Reached the goal after 84 timesteps\n",
      "Episode: 785 Training loss: 101.7945 Explore P: 0.1283\n",
      "56.17070063694268\n",
      "Episode: 786\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 786 Training loss: 101.1800 Explore P: 0.1283\n",
      "56.220101781170484\n",
      "Episode: 787\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 787 Training loss: 98.1336 Explore P: 0.1283\n",
      "56.26937738246506\n",
      "Episode: 788\n",
      "Reached the goal after 33 timesteps\n",
      "Episode: 788 Training loss: 83.2354 Explore P: 0.1282\n",
      "56.28299492385787\n",
      "Episode: 789\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 789 Training loss: 87.3588 Explore P: 0.1282\n",
      "56.32699619771863\n",
      "Episode: 790\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 790 Training loss: 85.5316 Explore P: 0.1282\n",
      "56.3746835443038\n",
      "Episode: 791\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 791 Training loss: 105.2758 Explore P: 0.1281\n",
      "56.418457648546145\n",
      "Episode: 792\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 792 Training loss: 106.4680 Explore P: 0.1281\n",
      "56.45959595959596\n",
      "Episode: 793\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 793 Training loss: 90.3743 Explore P: 0.1281\n",
      "56.49810844892812\n",
      "Episode: 794\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 794 Training loss: 96.5565 Explore P: 0.1280\n",
      "56.54030226700252\n",
      "Episode: 795\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 795 Training loss: 101.8273 Explore P: 0.1280\n",
      "56.5685534591195\n",
      "Episode: 796\n",
      "Reached the goal after 50 timesteps\n",
      "Episode: 796 Training loss: 79.7044 Explore P: 0.1278\n",
      "56.56030150753769\n",
      "Episode: 797\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 797 Training loss: 90.5047 Explore P: 0.1278\n",
      "56.60225846925972\n",
      "Episode: 798\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 798 Training loss: 87.0152 Explore P: 0.1278\n",
      "56.647869674185465\n",
      "Episode: 799\n",
      "Reached the goal after 19 timesteps\n",
      "Episode: 799 Training loss: 93.1049 Explore P: 0.1277\n",
      "56.67834793491865\n",
      "Episode: 800\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 800 Training loss: 104.4386 Explore P: 0.1277\n",
      "56.725\n",
      "Episode: 801\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 801 Training loss: 94.2309 Explore P: 0.1277\n",
      "56.77153558052434\n",
      "Episode: 802\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 802 Training loss: 109.9463 Explore P: 0.1276\n",
      "56.81047381546135\n",
      "Episode: 803\n",
      "Reached the goal after 22 timesteps\n",
      "Episode: 803 Training loss: 89.6860 Explore P: 0.1276\n",
      "56.83686176836862\n",
      "Episode: 804\n",
      "Reached the goal after 28 timesteps\n",
      "Episode: 804 Training loss: 93.3306 Explore P: 0.1275\n",
      "56.85572139303483\n",
      "Episode: 805\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 805 Training loss: 83.3028 Explore P: 0.1274\n",
      "56.88819875776397\n",
      "Episode: 806\n",
      "Reached the goal after 17 timesteps\n",
      "Episode: 806 Training loss: 101.9161 Explore P: 0.1274\n",
      "56.92059553349876\n",
      "Episode: 807\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 807 Training loss: 85.2712 Explore P: 0.1274\n",
      "56.96902106567534\n",
      "Episode: 808\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 808 Training loss: 102.2008 Explore P: 0.1274\n",
      "57.01361386138614\n",
      "Episode: 809\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 809 Training loss: 107.0848 Explore P: 0.1273\n",
      "57.049443757725584\n",
      "Episode: 810\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 810 Training loss: 86.3055 Explore P: 0.1273\n",
      "57.09135802469136\n",
      "Episode: 811\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 811 Training loss: 94.6983 Explore P: 0.1273\n",
      "57.136868064118374\n",
      "Episode: 812\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 812 Training loss: 90.7371 Explore P: 0.1272\n",
      "57.18103448275862\n",
      "Episode: 813\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 813 Training loss: 99.1899 Explore P: 0.1272\n",
      "57.227552275522754\n",
      "Episode: 814\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 814 Training loss: 95.2385 Explore P: 0.1272\n",
      "57.27272727272727\n",
      "Episode: 815\n",
      "Reached the goal after 69 timesteps\n",
      "Episode: 815 Training loss: 81.8853 Explore P: 0.1270\n",
      "57.24049079754601\n",
      "Episode: 816\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 816 Training loss: 101.8344 Explore P: 0.1270\n",
      "57.279411764705884\n",
      "Episode: 817\n",
      "Reached the goal after 38 timesteps\n",
      "Episode: 817 Training loss: 89.4771 Explore P: 0.1269\n",
      "57.28518971848225\n",
      "Episode: 818\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 818 Training loss: 103.4428 Explore P: 0.1269\n",
      "57.3239608801956\n",
      "Episode: 819\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 819 Training loss: 88.4996 Explore P: 0.1268\n",
      "57.356532356532355\n",
      "Episode: 820\n",
      "Reached the goal after 485 timesteps\n",
      "Episode: 820 Training loss: 98.1962 Explore P: 0.1255\n",
      "56.81707317073171\n",
      "Episode: 821\n",
      "Reached the goal after 59 timesteps\n",
      "Episode: 821 Training loss: 95.5207 Explore P: 0.1254\n",
      "56.79780755176614\n",
      "Episode: 822\n",
      "Reached the goal after 61 timesteps\n",
      "Episode: 822 Training loss: 98.8029 Explore P: 0.1252\n",
      "56.776155717761554\n",
      "Episode: 823\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 823 Training loss: 72.3555 Explore P: 0.1252\n",
      "56.81044957472661\n",
      "Episode: 824\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 824 Training loss: 103.8757 Explore P: 0.1252\n",
      "56.851941747572816\n",
      "Episode: 825\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 825 Training loss: 111.6803 Explore P: 0.1251\n",
      "56.89575757575758\n",
      "Episode: 826\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 826 Training loss: 90.0137 Explore P: 0.1251\n",
      "56.93946731234867\n",
      "Episode: 827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 11 timesteps\n",
      "Episode: 827 Training loss: 85.0845 Explore P: 0.1251\n",
      "56.9782345828295\n",
      "Episode: 828\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 828 Training loss: 94.2785 Explore P: 0.1251\n",
      "57.018115942028984\n",
      "Episode: 829\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 829 Training loss: 87.5712 Explore P: 0.1250\n",
      "57.0627261761158\n",
      "Episode: 830\n",
      "Reached the goal after 21 timesteps\n",
      "Episode: 830 Training loss: 90.3662 Explore P: 0.1250\n",
      "57.089156626506025\n",
      "Episode: 831\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 831 Training loss: 88.2912 Explore P: 0.1250\n",
      "57.13357400722022\n",
      "Episode: 832\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 832 Training loss: 92.5628 Explore P: 0.1249\n",
      "57.17548076923077\n",
      "Episode: 833\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 833 Training loss: 84.9365 Explore P: 0.1249\n",
      "57.21488595438175\n",
      "Episode: 834\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 834 Training loss: 74.0004 Explore P: 0.1249\n",
      "57.26139088729017\n",
      "Episode: 835\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 835 Training loss: 78.1265 Explore P: 0.1249\n",
      "57.30538922155689\n",
      "Episode: 836\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 836 Training loss: 90.8536 Explore P: 0.1249\n",
      "57.34808612440192\n",
      "Episode: 837\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 837 Training loss: 92.0555 Explore P: 0.1248\n",
      "57.38709677419355\n",
      "Episode: 838\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 838 Training loss: 96.0375 Explore P: 0.1248\n",
      "57.43198090692124\n",
      "Episode: 839\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 839 Training loss: 103.1152 Explore P: 0.1248\n",
      "57.469606674612635\n",
      "Episode: 840\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 840 Training loss: 100.3661 Explore P: 0.1248\n",
      "57.50952380952381\n",
      "Episode: 841\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 841 Training loss: 80.0720 Explore P: 0.1248\n",
      "57.55053507728894\n",
      "Episode: 842\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 842 Training loss: 86.6708 Explore P: 0.1247\n",
      "57.590261282660336\n",
      "Episode: 843\n",
      "Reached the goal after 24 timesteps\n",
      "Episode: 843 Training loss: 72.2423 Explore P: 0.1247\n",
      "57.612099644128115\n",
      "Episode: 844\n",
      "Reached the goal after 42 timesteps\n",
      "Episode: 844 Training loss: 63.8852 Explore P: 0.1246\n",
      "57.61255924170616\n",
      "Episode: 845\n",
      "Reached the goal after 40 timesteps\n",
      "Episode: 845 Training loss: 83.7851 Explore P: 0.1245\n",
      "57.61538461538461\n",
      "Episode: 846\n",
      "Reached the goal after 33 timesteps\n",
      "Episode: 846 Training loss: 102.9952 Explore P: 0.1244\n",
      "57.62647754137116\n",
      "Episode: 847\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 847 Training loss: 98.2269 Explore P: 0.1243\n",
      "57.645808736717825\n",
      "Episode: 848\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 848 Training loss: 98.1685 Explore P: 0.1243\n",
      "57.6875\n",
      "Episode: 849\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 849 Training loss: 96.5802 Explore P: 0.1243\n",
      "57.72909305064782\n",
      "Episode: 850\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 850 Training loss: 89.6182 Explore P: 0.1243\n",
      "57.77058823529412\n",
      "Episode: 851\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 851 Training loss: 82.9575 Explore P: 0.1242\n",
      "57.810810810810814\n",
      "Episode: 852\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 852 Training loss: 95.3290 Explore P: 0.1242\n",
      "57.852112676056336\n",
      "Episode: 853\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 853 Training loss: 76.7045 Explore P: 0.1242\n",
      "57.89449003516999\n",
      "Episode: 854\n",
      "Reached the goal after 94 timesteps\n",
      "Episode: 854 Training loss: 87.1745 Explore P: 0.1240\n",
      "57.833723653395786\n",
      "Episode: 855\n",
      "Reached the goal after 18 timesteps\n",
      "Episode: 855 Training loss: 73.1691 Explore P: 0.1239\n",
      "57.861988304093565\n",
      "Episode: 856\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 856 Training loss: 81.0340 Explore P: 0.1239\n",
      "57.90303738317757\n",
      "Episode: 857\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 857 Training loss: 94.1690 Explore P: 0.1239\n",
      "57.947491248541425\n",
      "Episode: 858\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 858 Training loss: 91.3089 Explore P: 0.1239\n",
      "57.98368298368298\n",
      "Episode: 859\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 859 Training loss: 101.8546 Explore P: 0.1238\n",
      "58.022118742724096\n",
      "Episode: 860\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 860 Training loss: 87.1489 Explore P: 0.1238\n",
      "58.05930232558139\n",
      "Episode: 861\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 861 Training loss: 84.2283 Explore P: 0.1238\n",
      "58.095238095238095\n",
      "Episode: 862\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 862 Training loss: 69.1555 Explore P: 0.1238\n",
      "58.140371229698374\n",
      "Episode: 863\n",
      "Reached the goal after 22 timesteps\n",
      "Episode: 863 Training loss: 89.0787 Explore P: 0.1237\n",
      "58.163383545770564\n",
      "Episode: 864\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 864 Training loss: 82.9869 Explore P: 0.1237\n",
      "58.204861111111114\n",
      "Episode: 865\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 865 Training loss: 95.0575 Explore P: 0.1237\n",
      "58.24971098265896\n",
      "Episode: 866\n",
      "Reached the goal after 24 timesteps\n",
      "Episode: 866 Training loss: 85.5971 Explore P: 0.1236\n",
      "58.270207852194\n",
      "Episode: 867\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 867 Training loss: 90.3935 Explore P: 0.1236\n",
      "58.312572087658594\n",
      "Episode: 868\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 868 Training loss: 76.6366 Explore P: 0.1236\n",
      "58.34907834101382\n",
      "Episode: 869\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 869 Training loss: 81.0039 Explore P: 0.1236\n",
      "58.388952819332566\n",
      "Episode: 870\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 870 Training loss: 87.4318 Explore P: 0.1236\n",
      "58.42988505747127\n",
      "Episode: 871\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 871 Training loss: 82.6326 Explore P: 0.1235\n",
      "58.46383467278989\n",
      "Episode: 872\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 872 Training loss: 81.7965 Explore P: 0.1235\n",
      "58.50573394495413\n",
      "Episode: 873\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 873 Training loss: 88.4888 Explore P: 0.1235\n",
      "58.54868270332188\n",
      "Episode: 874\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 874 Training loss: 81.6336 Explore P: 0.1235\n",
      "58.58695652173913\n",
      "Episode: 875\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 875 Training loss: 79.3209 Explore P: 0.1235\n",
      "58.628571428571426\n",
      "Episode: 876\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 876 Training loss: 96.9782 Explore P: 0.1234\n",
      "58.66438356164384\n",
      "Episode: 877\n",
      "Reached the goal after 30 timesteps\n",
      "Episode: 877 Training loss: 82.2103 Explore P: 0.1234\n",
      "58.677309007981755\n",
      "Episode: 878\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 878 Training loss: 95.6020 Explore P: 0.1233\n",
      "58.71184510250569\n",
      "Episode: 879\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 879 Training loss: 91.5867 Explore P: 0.1233\n",
      "58.75199089874858\n",
      "Episode: 880\n",
      "Reached the goal after 44 timesteps\n",
      "Episode: 880 Training loss: 85.1095 Explore P: 0.1232\n",
      "58.74886363636364\n",
      "Episode: 881\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 881 Training loss: 121.2957 Explore P: 0.1232\n",
      "58.7900113507378\n",
      "Episode: 882\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 882 Training loss: 77.8229 Explore P: 0.1232\n",
      "58.82993197278912\n",
      "Episode: 883\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 883 Training loss: 94.1639 Explore P: 0.1232\n",
      "58.86636466591167\n",
      "Episode: 884\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 884 Training loss: 95.0050 Explore P: 0.1231\n",
      "58.90045248868778\n",
      "Episode: 885\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 885 Training loss: 85.9564 Explore P: 0.1231\n",
      "58.94011299435028\n",
      "Episode: 886\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 886 Training loss: 89.4661 Explore P: 0.1231\n",
      "58.97404063205418\n",
      "Episode: 887\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 887 Training loss: 87.5507 Explore P: 0.1231\n",
      "59.00901916572717\n",
      "Episode: 888\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 888 Training loss: 98.7369 Explore P: 0.1230\n",
      "59.04504504504504\n",
      "Episode: 889\n",
      "Reached the goal after 40 timesteps\n",
      "Episode: 889 Training loss: 101.0099 Explore P: 0.1229\n",
      "59.04611923509561\n",
      "Episode: 890\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 890 Training loss: 79.6136 Explore P: 0.1229\n",
      "59.08651685393259\n",
      "Episode: 891\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 891 Training loss: 95.4324 Explore P: 0.1229\n",
      "59.12457912457913\n",
      "Episode: 892\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 892 Training loss: 98.6334 Explore P: 0.1229\n",
      "59.16143497757847\n",
      "Episode: 893\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 893 Training loss: 97.2581 Explore P: 0.1229\n",
      "59.200447928331464\n",
      "Episode: 894\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 894 Training loss: 82.2318 Explore P: 0.1229\n",
      "59.238255033557046\n",
      "Episode: 895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 5 timesteps\n",
      "Episode: 895 Training loss: 97.4808 Explore P: 0.1228\n",
      "59.27821229050279\n",
      "Episode: 896\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 896 Training loss: 96.1537 Explore P: 0.1228\n",
      "59.3125\n",
      "Episode: 897\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 897 Training loss: 108.3931 Explore P: 0.1228\n",
      "59.34782608695652\n",
      "Episode: 898\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 898 Training loss: 91.9680 Explore P: 0.1228\n",
      "59.38641425389755\n",
      "Episode: 899\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 899 Training loss: 91.6152 Explore P: 0.1228\n",
      "59.4238042269188\n",
      "Episode: 900\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 900 Training loss: 104.2042 Explore P: 0.1227\n",
      "59.458888888888886\n",
      "Episode: 901\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 901 Training loss: 87.5249 Explore P: 0.1227\n",
      "59.49500554938957\n",
      "Episode: 902\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 902 Training loss: 98.2428 Explore P: 0.1227\n",
      "59.534368070953434\n",
      "Episode: 903\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 903 Training loss: 92.3932 Explore P: 0.1227\n",
      "59.57475083056478\n",
      "Episode: 904\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 904 Training loss: 106.2171 Explore P: 0.1227\n",
      "59.61504424778761\n",
      "Episode: 905\n",
      "Reached the goal after 18 timesteps\n",
      "Episode: 905 Training loss: 101.5304 Explore P: 0.1226\n",
      "59.639779005524865\n",
      "Episode: 906\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 906 Training loss: 98.7626 Explore P: 0.1226\n",
      "59.68101545253863\n",
      "Episode: 907\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 907 Training loss: 86.6076 Explore P: 0.1226\n",
      "59.7199558985667\n",
      "Episode: 908\n",
      "Reached the goal after 33 timesteps\n",
      "Episode: 908 Training loss: 83.5113 Explore P: 0.1225\n",
      "59.72797356828194\n",
      "Episode: 909\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 909 Training loss: 87.7560 Explore P: 0.1225\n",
      "59.766776677667764\n",
      "Episode: 910\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 910 Training loss: 90.2503 Explore P: 0.1225\n",
      "59.8021978021978\n",
      "Episode: 911\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 911 Training loss: 93.3323 Explore P: 0.1225\n",
      "59.834248079034026\n",
      "Episode: 912\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 912 Training loss: 86.8766 Explore P: 0.1225\n",
      "59.862938596491226\n",
      "Episode: 913\n",
      "Reached the goal after 130 timesteps\n",
      "Episode: 913 Training loss: 105.4343 Explore P: 0.1222\n",
      "59.7645125958379\n",
      "Episode: 914\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 914 Training loss: 90.1492 Explore P: 0.1221\n",
      "59.80196936542669\n",
      "Episode: 915\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 915 Training loss: 105.4513 Explore P: 0.1221\n",
      "59.83715846994536\n",
      "Episode: 916\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 916 Training loss: 90.2560 Explore P: 0.1221\n",
      "59.87117903930131\n",
      "Episode: 917\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 917 Training loss: 97.1604 Explore P: 0.1221\n",
      "59.904034896401306\n",
      "Episode: 918\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 918 Training loss: 114.3362 Explore P: 0.1221\n",
      "59.9400871459695\n",
      "Episode: 919\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 919 Training loss: 87.4180 Explore P: 0.1220\n",
      "59.97606093579978\n",
      "Episode: 920\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 920 Training loss: 83.0039 Explore P: 0.1220\n",
      "60.01086956521739\n",
      "Episode: 921\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 921 Training loss: 80.1978 Explore P: 0.1220\n",
      "60.047774158523346\n",
      "Episode: 922\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 922 Training loss: 90.0882 Explore P: 0.1220\n",
      "60.07700650759219\n",
      "Episode: 923\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 923 Training loss: 86.2308 Explore P: 0.1220\n",
      "60.11267605633803\n",
      "Episode: 924\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 924 Training loss: 120.4364 Explore P: 0.1219\n",
      "60.146103896103895\n",
      "Episode: 925\n",
      "Reached the goal after 41 timesteps\n",
      "Episode: 925 Training loss: 90.3611 Explore P: 0.1218\n",
      "60.144864864864864\n",
      "Episode: 926\n",
      "Reached the goal after 11 timesteps\n",
      "Episode: 926 Training loss: 93.0917 Explore P: 0.1218\n",
      "60.176025917926566\n",
      "Episode: 927\n",
      "Reached the goal after 49 timesteps\n",
      "Episode: 927 Training loss: 89.5248 Explore P: 0.1217\n",
      "60.16612729234088\n",
      "Episode: 928\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 928 Training loss: 105.4376 Explore P: 0.1217\n",
      "60.199353448275865\n",
      "Episode: 929\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 929 Training loss: 100.3762 Explore P: 0.1217\n",
      "60.23573735199139\n",
      "Episode: 930\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 930 Training loss: 105.6536 Explore P: 0.1217\n",
      "60.26989247311828\n",
      "Episode: 931\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 931 Training loss: 79.3191 Explore P: 0.1216\n",
      "60.30397422126745\n",
      "Episode: 932\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 932 Training loss: 84.0006 Explore P: 0.1216\n",
      "60.337982832618025\n",
      "Episode: 933\n",
      "Reached the goal after 37 timesteps\n",
      "Episode: 933 Training loss: 91.9293 Explore P: 0.1215\n",
      "60.340836012861736\n",
      "Episode: 934\n",
      "Reached the goal after 44 timesteps\n",
      "Episode: 934 Training loss: 91.3362 Explore P: 0.1214\n",
      "60.33618843683084\n",
      "Episode: 935\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 935 Training loss: 88.7962 Explore P: 0.1214\n",
      "60.37219251336899\n",
      "Episode: 936\n",
      "Reached the goal after 13 timesteps\n",
      "Episode: 936 Training loss: 79.2186 Explore P: 0.1214\n",
      "60.40064102564103\n",
      "Episode: 937\n",
      "Reached the goal after 16 timesteps\n",
      "Episode: 937 Training loss: 86.2218 Explore P: 0.1214\n",
      "60.42582710779082\n",
      "Episode: 938\n",
      "Reached the goal after 103 timesteps\n",
      "Episode: 938 Training loss: 98.6035 Explore P: 0.1211\n",
      "60.35820895522388\n",
      "Episode: 939\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 939 Training loss: 99.9902 Explore P: 0.1211\n",
      "60.39297124600639\n",
      "Episode: 940\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 940 Training loss: 85.4176 Explore P: 0.1211\n",
      "60.42553191489362\n",
      "Episode: 941\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 941 Training loss: 80.9796 Explore P: 0.1211\n",
      "60.46227417640808\n",
      "Episode: 942\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 942 Training loss: 114.0961 Explore P: 0.1211\n",
      "60.49787685774947\n",
      "Episode: 943\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 943 Training loss: 96.9649 Explore P: 0.1211\n",
      "60.5355249204666\n",
      "Episode: 944\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 944 Training loss: 83.8809 Explore P: 0.1210\n",
      "60.57203389830509\n",
      "Episode: 945\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 945 Training loss: 88.0879 Explore P: 0.1210\n",
      "60.6010582010582\n",
      "Episode: 946\n",
      "Reached the goal after 39 timesteps\n",
      "Episode: 946 Training loss: 99.9134 Explore P: 0.1209\n",
      "60.6014799154334\n",
      "Episode: 947\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 947 Training loss: 97.2681 Explore P: 0.1209\n",
      "60.63463569165787\n",
      "Episode: 948\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 948 Training loss: 86.7206 Explore P: 0.1209\n",
      "60.67194092827004\n",
      "Episode: 949\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 949 Training loss: 79.4116 Explore P: 0.1209\n",
      "60.70811380400421\n",
      "Episode: 950\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 950 Training loss: 90.7400 Explore P: 0.1209\n",
      "60.74526315789473\n",
      "Episode: 951\n",
      "Reached the goal after 272 timesteps\n",
      "Episode: 951 Training loss: 87.2857 Explore P: 0.1203\n",
      "60.500525762355416\n",
      "Episode: 952\n",
      "Reached the goal after 14 timesteps\n",
      "Episode: 952 Training loss: 85.9982 Explore P: 0.1203\n",
      "60.52731092436975\n",
      "Episode: 953\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 953 Training loss: 89.8512 Explore P: 0.1203\n",
      "60.561385099685204\n",
      "Episode: 954\n",
      "Reached the goal after 20 timesteps\n",
      "Episode: 954 Training loss: 96.8252 Explore P: 0.1202\n",
      "60.581761006289305\n",
      "Episode: 955\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 955 Training loss: 84.4447 Explore P: 0.1202\n",
      "60.617801047120416\n",
      "Episode: 956\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 956 Training loss: 89.1665 Explore P: 0.1202\n",
      "60.65271966527197\n",
      "Episode: 957\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 957 Training loss: 94.7056 Explore P: 0.1201\n",
      "60.666666666666664\n",
      "Episode: 958\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 958 Training loss: 82.7860 Explore P: 0.1201\n",
      "60.70459290187891\n",
      "Episode: 959\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 959 Training loss: 86.6042 Explore P: 0.1201\n",
      "60.74035453597497\n",
      "Episode: 960\n",
      "Reached the goal after 216 timesteps\n",
      "Episode: 960 Training loss: 85.8640 Explore P: 0.1197\n",
      "60.55625\n",
      "Episode: 961\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 961 Training loss: 95.4297 Explore P: 0.1197\n",
      "60.592091571279916\n",
      "Episode: 962\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 962 Training loss: 101.1427 Explore P: 0.1197\n",
      "60.62681912681913\n",
      "Episode: 963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the goal after 11 timesteps\n",
      "Episode: 963 Training loss: 69.0565 Explore P: 0.1196\n",
      "60.65628245067497\n",
      "Episode: 964\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 964 Training loss: 69.5074 Explore P: 0.1196\n",
      "60.689834024896264\n",
      "Episode: 965\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 965 Training loss: 80.6988 Explore P: 0.1196\n",
      "60.722279792746114\n",
      "Episode: 966\n",
      "Reached the goal after 88 timesteps\n",
      "Episode: 966 Training loss: 91.1041 Explore P: 0.1194\n",
      "60.67184265010352\n",
      "Episode: 967\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 967 Training loss: 82.4809 Explore P: 0.1194\n",
      "60.70423991726991\n",
      "Episode: 968\n",
      "Reached the goal after 27 timesteps\n",
      "Episode: 968 Training loss: 88.9791 Explore P: 0.1194\n",
      "60.71694214876033\n",
      "Episode: 969\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 969 Training loss: 82.1577 Explore P: 0.1194\n",
      "60.75025799793602\n",
      "Episode: 970\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 970 Training loss: 72.3213 Explore P: 0.1193\n",
      "60.78556701030928\n",
      "Episode: 971\n",
      "Reached the goal after 144 timesteps\n",
      "Episode: 971 Training loss: 78.5426 Explore P: 0.1191\n",
      "60.67765190525232\n",
      "Episode: 972\n",
      "Reached the goal after 4 timesteps\n",
      "Episode: 972 Training loss: 99.9706 Explore P: 0.1191\n",
      "60.71399176954733\n",
      "Episode: 973\n",
      "Reached the goal after 69 timesteps\n",
      "Episode: 973 Training loss: 66.5499 Explore P: 0.1189\n",
      "60.68345323741007\n",
      "Episode: 974\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 974 Training loss: 82.8731 Explore P: 0.1189\n",
      "60.7135523613963\n",
      "Episode: 975\n",
      "Reached the goal after 8 timesteps\n",
      "Episode: 975 Training loss: 81.9830 Explore P: 0.1189\n",
      "60.74564102564103\n",
      "Episode: 976\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 976 Training loss: 89.3879 Explore P: 0.1189\n",
      "60.779713114754095\n",
      "Episode: 977\n",
      "Reached the goal after 40 timesteps\n",
      "Episode: 977 Training loss: 82.0728 Explore P: 0.1188\n",
      "60.77891504605937\n",
      "Episode: 978\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 978 Training loss: 91.8917 Explore P: 0.1188\n",
      "60.80879345603272\n",
      "Episode: 979\n",
      "Reached the goal after 26 timesteps\n",
      "Episode: 979 Training loss: 83.4289 Explore P: 0.1187\n",
      "60.822267620020426\n",
      "Episode: 980\n",
      "Reached the goal after 62 timesteps\n",
      "Episode: 980 Training loss: 87.0818 Explore P: 0.1186\n",
      "60.79897959183673\n",
      "Episode: 981\n",
      "Reached the goal after 12 timesteps\n",
      "Episode: 981 Training loss: 91.8833 Explore P: 0.1186\n",
      "60.82670744138634\n",
      "Episode: 982\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 982 Training loss: 76.9206 Explore P: 0.1186\n",
      "60.85947046843177\n",
      "Episode: 983\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 983 Training loss: 93.5235 Explore P: 0.1185\n",
      "60.890132248219736\n",
      "Episode: 984\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 984 Training loss: 87.2037 Explore P: 0.1185\n",
      "60.923780487804876\n",
      "Episode: 985\n",
      "Reached the goal after 2 timesteps\n",
      "Episode: 985 Training loss: 82.9272 Explore P: 0.1185\n",
      "60.961421319796955\n",
      "Episode: 986\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 986 Training loss: 75.2124 Explore P: 0.1185\n",
      "60.99087221095335\n",
      "Episode: 987\n",
      "Reached the goal after 265 timesteps\n",
      "Episode: 987 Training loss: 98.5842 Explore P: 0.1180\n",
      "60.76190476190476\n",
      "Episode: 988\n",
      "Reached the goal after 15 timesteps\n",
      "Episode: 988 Training loss: 82.1890 Explore P: 0.1180\n",
      "60.786437246963565\n",
      "Episode: 989\n",
      "Reached the goal after 9 timesteps\n",
      "Episode: 989 Training loss: 97.0210 Explore P: 0.1180\n",
      "60.8169868554095\n",
      "Episode: 990\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 990 Training loss: 87.0256 Explore P: 0.1180\n",
      "60.846464646464646\n",
      "Episode: 991\n",
      "Reached the goal after 6 timesteps\n",
      "Episode: 991 Training loss: 80.4046 Explore P: 0.1179\n",
      "60.87991927346115\n",
      "Episode: 992\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 992 Training loss: 86.8137 Explore P: 0.1179\n",
      "60.91633064516129\n",
      "Episode: 993\n",
      "Reached the goal after 7 timesteps\n",
      "Episode: 993 Training loss: 81.1660 Explore P: 0.1179\n",
      "60.948640483383684\n",
      "Episode: 994\n",
      "Reached the goal after 65 timesteps\n",
      "Episode: 994 Training loss: 89.6838 Explore P: 0.1178\n",
      "60.92253521126761\n",
      "Episode: 995\n",
      "Reached the goal after 28 timesteps\n",
      "Episode: 995 Training loss: 79.1164 Explore P: 0.1178\n",
      "60.93366834170854\n",
      "Episode: 996\n",
      "Reached the goal after 5 timesteps\n",
      "Episode: 996 Training loss: 55.5680 Explore P: 0.1177\n",
      "60.967871485943775\n",
      "Episode: 997\n",
      "Reached the goal after 3 timesteps\n",
      "Episode: 997 Training loss: 103.8653 Explore P: 0.1177\n",
      "61.00401203610833\n",
      "Episode: 998\n",
      "Reached the goal after 10 timesteps\n",
      "Episode: 998 Training loss: 90.3236 Explore P: 0.1177\n",
      "61.03306613226453\n",
      "Episode: 999\n",
      "Reached the goal after 39 timesteps\n",
      "Episode: 999 Training loss: 77.0957 Explore P: 0.1176\n",
      "61.033033033033036\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetNetwork(trainables)\n",
    "\n",
    "cum_avg_reward_lst = []\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(init)\n",
    "\n",
    "    step = 0\n",
    "    total_reward = 0\n",
    "    for ep in range(1, train_episodes):\n",
    "        state, reward, done, _ = env.reset()\n",
    "        print('Episode: ' + str(ep))\n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render()\n",
    "\n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step)\n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "\n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            total_reward += reward\n",
    "            goals_sample = memory.sample_goals(k)\n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                #next_state = np.zeros(state.shape)\n",
    "                print(\"Reached the goal after {} timesteps\".format(t))\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                # Add experience to memory\n",
    "                memory.add_transition((state, action, reward, next_state))\n",
    "\n",
    "                for goal in goals_sample:\n",
    "                    #print(goal)\n",
    "                    #print(next_state)\n",
    "                    if np.array_equal(next_state, goal):\n",
    "                        memory.add_transition((state,action,100,next_state))\n",
    "                    else:\n",
    "                        memory.add_transition((state,action,-1,next_state))\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                # If is the last step in the episode and goal isnt Reached\n",
    "                # return reward 100, since final state is emulating goal\n",
    "                # if t+1 == max_steps:\n",
    "                memory.add_transition((state, action, reward, next_state))\n",
    "                for goal in goals_sample:\n",
    "                    #print(goal)\n",
    "                    #print(next_state)\n",
    "                    if np.array_equal(next_state, goal):\n",
    "                        memory.add_transition((state,action,100,next_state))\n",
    "                    else:\n",
    "                        memory.add_transition((state,action,-1,next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "\n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample_transitions(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "\n",
    "            # Train network\n",
    "            target_Qs = sess.run(targetQN.output, feed_dict={targetQN.inputs_: next_states})\n",
    "\n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
    "\n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "            # After every C steps copy Q network to target network periodically\n",
    "            # use target network to calculate target Qs\n",
    "            if  t % c_steps == 0:\n",
    "               updateTarget(targetOps,sess)\n",
    "\n",
    "            if done: break\n",
    "            elif t == max_steps:\n",
    "                memory.add_goal(state)\n",
    "        cum_avg_reward = total_reward/(ep)\n",
    "        cum_avg_reward_lst.append(cum_avg_reward)\n",
    "        print(cum_avg_reward)\n",
    "\n",
    "    saver.save(sess, \"checkpoints_her/putballinbox\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cum_avg_reward_lst)\n",
    "plt.ylabel('Avg cumulative reward')\n",
    "plt.xlabel('Episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints_her/putballinbox\n",
      "Episode: 1\n",
      "Reached the goal after 10 timesteps\n",
      "91.0\n",
      "Episode: 2\n",
      "Reached the goal after 7 timesteps\n",
      "92.5\n",
      "Episode: 3\n",
      "Reached the goal after 10 timesteps\n",
      "92.0\n",
      "Episode: 4\n",
      "Didnt reach the goal after 20 timesteps\n",
      "64.0\n",
      "Episode: 5\n",
      "Reached the goal after 6 timesteps\n",
      "70.2\n",
      "Episode: 6\n",
      "Reached the goal after 4 timesteps\n",
      "74.66666666666667\n",
      "Episode: 7\n",
      "Didnt reach the goal after 20 timesteps\n",
      "61.142857142857146\n",
      "Episode: 8\n",
      "Reached the goal after 6 timesteps\n",
      "65.375\n",
      "Episode: 9\n",
      "Didnt reach the goal after 20 timesteps\n",
      "55.888888888888886\n",
      "Episode: 10\n",
      "Reached the goal after 8 timesteps\n",
      "59.6\n"
     ]
    }
   ],
   "source": [
    "# Test the trained DQN + HER model\n",
    "import time\n",
    "import copy\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Load meta graph and restore weights\n",
    "    saver = tf.train.import_meta_graph('checkpoints_her/putballinbox.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('checkpoints_her/'))\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    inputs_tensor = graph.get_tensor_by_name(\"main/inputs:0\")\n",
    "    output_tensor = graph.get_tensor_by_name(\"main/fully_connected_3/BiasAdd:0\")\n",
    "\n",
    "\n",
    "    target_output_tensor = tf.contrib.copy_graph.get_copied_op(output_tensor, graph)\n",
    "\n",
    "    total_reward = 0\n",
    "    n_episodes = 10\n",
    "    n_steps = 20\n",
    "\n",
    "    for i_episode in range(n_episodes):\n",
    "        print('Episode: ' + str(i_episode+1))\n",
    "        state,_,_,_ = env.reset()\n",
    "        for t in range(n_steps):\n",
    "            env.render()\n",
    "            feed = {inputs_tensor: state.reshape((1, *state.shape))}\n",
    "            Qs = sess.run(target_output_tensor, feed_dict=feed)\n",
    "            action = np.argmax(Qs)\n",
    "            next_state, r, done, _ = env.step(action)\n",
    "            state = next_state\n",
    "            total_reward += r\n",
    "            if done:\n",
    "                print(\"Reached the goal after {} timesteps\".format(t+1))\n",
    "                break\n",
    "            time.sleep(0.5)\n",
    "        if not done:\n",
    "            print(\"Didnt reach the goal after {} timesteps\".format(n_steps))\n",
    "        print(total_reward/(i_episode + 1))\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
